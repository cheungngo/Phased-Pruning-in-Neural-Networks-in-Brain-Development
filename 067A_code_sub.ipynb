{"cells":[{"cell_type":"markdown","metadata":{"id":"vABcCl65a85x"},"source":["# ASD Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2MBOKNWLpmj7","outputId":"bf6a3355-4bfa-4fca-ebce-6fb6cba775e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","################################################################################\n","#                   DEVELOPMENTAL PRUNING SIMULATION FOR ASD                   #\n","#             VERSION 9.2: DENSITY SWEEP WITH DIFFERENTIAL PRUNING             #\n","#                              EXPERIMENT 1 ONLY                               #\n","################################################################################\n","\n"," ============================================================================\n"," EXPERIMENT 1: DENSITY SWEEP WITH DIFFERENTIAL LATE PRUNING\n"," ============================================================================\n","\n"," OBJECTIVE:\n"," ----------\n"," Understand how initial network density (early pruning) affects:\n","   1. Learning capacity and task performance\n","   2. Resilience to subsequent pruning\n","   3. Differential outcomes between Normal and ASD pruning regimes\n","\n"," EARLY STAGE:\n"," ------------\n","   • Test densities: 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%\n","   • Each model starts from trained baseline\n","   • Prune to target density, then train for 15 epochs\n","   • Evaluate on: accuracy, stress tolerance, ambiguity handling\n","\n"," LATE STAGE:\n"," -----------\n","   • For each early density, create two conditions:\n","     - Normal: Remove 20% of remaining weights\n","     - ASD: Remove 50% of remaining weights\n","   • Fine-tune each for 10 epochs\n","   • Compare Normal vs ASD outcomes\n","\n"," METRICS:\n"," --------\n","   • Visual task accuracy (primary)\n","   • Voice task accuracy (secondary, conflicting task)\n","   • Stress tolerance (performance under noise injection)\n","   • Ambiguity tolerance (performance with mixed task signals)\n","   • Blended input handling (combining sensory streams)\n","\n"," ============================================================================\n","    \n","\n"," Starting Experiment 1...\n","\n","################################################################################\n","#          EXPERIMENT 1: DENSITY SWEEP WITH DIFFERENTIAL LATE PRUNING          #\n","#            Version 9.2: Comprehensive Early/Late Stage Comparison            #\n","################################################################################\n","\n"," EXPERIMENTAL DESIGN:\n"," ====================\n","\n"," EARLY STAGE (density sweep):\n","   Densities tested: ['10%', '20%', '30%', '40%', '50%', '60%', '70%', '80%', '90%', '100%']\n","   Training epochs per density: 15\n","   Learning rate: 0.0005\n","\n"," LATE STAGE (differential pruning from each early state):\n","   Normal condition: Remove 20% of remaining weights\n","   ASD condition: Remove 50% of remaining weights\n","   Fine-tuning epochs: 10\n","\n"," RATIONALE:\n","   This design tests how initial network density (early pruning) affects:\n","   1. Baseline learning capacity\n","   2. Resilience to further pruning (late stage)\n","   3. The differential impact of normal vs. excessive late pruning\n","    \n","\n","======================================================================\n"," CREATING TASK-GATED MULTI-TASK DATA LOADERS\n","======================================================================\n","\n"," Generating Visual Task Data...\n","   - Training samples: 12,000\n","   - Test samples: 4,000\n","   - Clean test samples: 2,000\n","   - Noise level: 0.8\n","   - Cluster centers: [[-3, -3], [3, 3], [-3, 3], [3, -3]]\n","\n"," Generating Voice Task Data (CONFLICTING labels)...\n","   - Training samples: 12,000\n","   - Test samples: 4,000\n","   - Noise level: 0.8\n","   - Label permutation: [2, 3, 0, 1]\n","   - NOTE: Same spatial distribution as visual, but labels are permuted\n","\n"," Data Loaders Created Successfully:\n","   - Visual train loader: 94 batches\n","   - Visual test loader: 4 batches\n","   - Voice train loader: 94 batches\n","   - Voice test loader: 4 batches\n","   - Batch size: 128\n","\n","================================================================================\n"," STAGE 0: TRAINING FULL DENSITY BASELINE\n","================================================================================\n","\n"," Creating full density network...\n","\n","--------------------------------------------------\n"," NETWORK ARCHITECTURE\n","--------------------------------------------------\n","   Input dimension: 2 + 2 (task ID) = 4\n","   Hidden layers: [256, 256, 128]\n","   Output dimension: 4\n","\n","   Layer Details:\n","     fc1.weight: [256, 4]\n","     fc1.bias: [256]\n","     fc2.weight: [256, 256]\n","     fc2.bias: [256]\n","     fc3.weight: [128, 256]\n","     fc3.bias: [128]\n","     head.weight: [4, 128]\n","     head.bias: [4]\n","\n","   Total parameters: 100,484\n","   Non-zero parameters: 100,484\n","--------------------------------------------------\n","\n"," Training baseline model for 30 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 30\n","     - Learning rate: 0.001\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","\n","    Epoch   5/30: Loss V=0.0004 A=0.0004 Combined=0.0004 | Acc V=100.0% A=100.0%\n","    Epoch  10/30: Loss V=0.0001 A=0.0005 Combined=0.0003 | Acc V=100.0% A=100.0%\n","    Epoch  15/30: Loss V=0.0001 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  20/30: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  25/30: Loss V=0.0000 A=0.0006 Combined=0.0003 | Acc V=100.0% A=100.0%\n","    Epoch  30/30: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: FULL DENSITY BASELINE (100%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 100,484\n","   Density: 100.0%\n","   Sparsity: 0.0%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 96.7% (drop: +3.2%)\n","         High (σ=2.0): 83.0% (drop: +17.0%)\n","       Severe (σ=3.0): 68.8% (drop: +31.2%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 98.4% (drop: +1.6%)\n","           High (w=0.60): 77.0% (drop: +22.9%)\n","         Severe (w=0.55): 75.6% (drop: +24.4%)\n","      Ambiguous (w=0.50): 74.1% (drop: +25.9%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 44.3%\n","   30% blend + clear context: 97.0%\n","   50% blend + clear context: 57.5%\n","\n"," Baseline state saved for density sweep experiments.\n","\n","================================================================================\n"," EARLY STAGE: DENSITY SWEEP (10% to 100%)\n"," Comparing learning dynamics across density levels\n","================================================================================\n","\n"," Testing 10 density levels...\n"," Each model starts from baseline, is pruned to target density, then trained for 15 epochs.\n","\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 1/10: 10%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 10% density...\n","   Pruning complete:\n","     fc1.weight: kept 103/1,024 weights (10.1% density)\n","     fc2.weight: kept 6,554/65,536 weights (10.0% density)\n","     fc3.weight: kept 3,277/32,768 weights (10.0% density)\n","     head.weight: kept 52/512 weights (10.2% density)\n","\n","   Mask Statistics (Target: 10%):\n","     fc1.weight: 103/1,024 active (10.1%)\n","     fc2.weight: 6,554/65,536 active (10.0%)\n","     fc3.weight: 3,277/32,768 active (10.0%)\n","     head.weight: 52/512 active (10.2%)\n","     TOTAL: 9,986/99,840 active (10.0%)\n","\n","   Training for 15 epochs at 10.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=10.0%)\n","\n","    Epoch   5/15: Loss V=0.0674 A=0.7145 Combined=0.3909 | Acc V=99.7% A=49.9%\n","    Epoch  10/15: Loss V=0.0088 A=0.6980 Combined=0.3534 | Acc V=99.9% A=49.2%\n","    Epoch  15/15: Loss V=0.0033 A=0.6967 Combined=0.3500 | Acc V=100.0% A=50.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.3500\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 50.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 10% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 10,630\n","   Density: 10.6%\n","   Sparsity: 89.4%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 50.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 88.3% (drop: +11.7%)\n","     Moderate (σ=1.0): 64.9% (drop: +35.0%)\n","         High (σ=2.0): 45.0% (drop: +55.0%)\n","       Severe (σ=3.0): 35.9% (drop: +64.1%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 100.0% (drop: -0.0%)\n","         Severe (w=0.55): 99.9% (drop: +0.0%)\n","      Ambiguous (w=0.50): 100.0% (drop: +0.0%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 56.5%\n","   30% blend + clear context: 95.5%\n","   50% blend + clear context: 56.6%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 2/10: 20%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 20% density...\n","   Pruning complete:\n","     fc1.weight: kept 205/1,024 weights (20.0% density)\n","     fc2.weight: kept 13,108/65,536 weights (20.0% density)\n","     fc3.weight: kept 6,554/32,768 weights (20.0% density)\n","     head.weight: kept 103/512 weights (20.1% density)\n","\n","   Mask Statistics (Target: 20%):\n","     fc1.weight: 205/1,024 active (20.0%)\n","     fc2.weight: 13,108/65,536 active (20.0%)\n","     fc3.weight: 6,554/32,768 active (20.0%)\n","     head.weight: 103/512 active (20.1%)\n","     TOTAL: 19,970/99,840 active (20.0%)\n","\n","   Training for 15 epochs at 20.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=20.0%)\n","\n","    Epoch   5/15: Loss V=0.0007 A=0.0014 Combined=0.0011 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0002 A=0.0004 Combined=0.0003 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0001 A=0.0002 Combined=0.0002 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0002\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 20% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 20,614\n","   Density: 20.5%\n","   Sparsity: 79.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 96.2% (drop: +3.8%)\n","     Moderate (σ=1.0): 76.5% (drop: +23.4%)\n","         High (σ=2.0): 53.5% (drop: +46.5%)\n","       Severe (σ=3.0): 44.2% (drop: +55.8%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 92.3% (drop: +7.6%)\n","         Severe (w=0.55): 77.4% (drop: +22.5%)\n","      Ambiguous (w=0.50): 69.3% (drop: +30.7%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 46.9%\n","   30% blend + clear context: 97.0%\n","   50% blend + clear context: 55.8%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 3/10: 30%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 30% density...\n","   Pruning complete:\n","     fc1.weight: kept 307/1,024 weights (30.0% density)\n","     fc2.weight: kept 19,661/65,536 weights (30.0% density)\n","     fc3.weight: kept 9,831/32,768 weights (30.0% density)\n","     head.weight: kept 154/512 weights (30.1% density)\n","\n","   Mask Statistics (Target: 30%):\n","     fc1.weight: 307/1,024 active (30.0%)\n","     fc2.weight: 19,661/65,536 active (30.0%)\n","     fc3.weight: 9,831/32,768 active (30.0%)\n","     head.weight: 154/512 active (30.1%)\n","     TOTAL: 29,953/99,840 active (30.0%)\n","\n","   Training for 15 epochs at 30.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=30.0%)\n","\n","    Epoch   5/15: Loss V=0.0001 A=0.0003 Combined=0.0002 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 30% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 30,597\n","   Density: 30.4%\n","   Sparsity: 69.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 98.9% (drop: +1.1%)\n","     Moderate (σ=1.0): 88.5% (drop: +11.4%)\n","         High (σ=2.0): 66.1% (drop: +33.8%)\n","       Severe (σ=3.0): 54.2% (drop: +45.8%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 99.7% (drop: +0.3%)\n","         Severe (w=0.55): 82.2% (drop: +17.8%)\n","      Ambiguous (w=0.50): 75.2% (drop: +24.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 47.0%\n","   30% blend + clear context: 96.9%\n","   50% blend + clear context: 55.7%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 4/10: 40%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 40% density...\n","   Pruning complete:\n","     fc1.weight: kept 410/1,024 weights (40.0% density)\n","     fc2.weight: kept 26,215/65,536 weights (40.0% density)\n","     fc3.weight: kept 13,107/32,768 weights (40.0% density)\n","     head.weight: kept 205/512 weights (40.0% density)\n","\n","   Mask Statistics (Target: 40%):\n","     fc1.weight: 410/1,024 active (40.0%)\n","     fc2.weight: 26,215/65,536 active (40.0%)\n","     fc3.weight: 13,107/32,768 active (40.0%)\n","     head.weight: 205/512 active (40.0%)\n","     TOTAL: 39,937/99,840 active (40.0%)\n","\n","   Training for 15 epochs at 40.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=40.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0001 A=0.0005 Combined=0.0003 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0003\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 40% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 40,581\n","   Density: 40.4%\n","   Sparsity: 59.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.2% (drop: +0.8%)\n","     Moderate (σ=1.0): 92.6% (drop: +7.4%)\n","         High (σ=2.0): 72.8% (drop: +27.1%)\n","       Severe (σ=3.0): 60.2% (drop: +39.7%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.0%)\n","           High (w=0.60): 91.6% (drop: +8.4%)\n","         Severe (w=0.55): 80.2% (drop: +19.8%)\n","      Ambiguous (w=0.50): 75.5% (drop: +24.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 48.5%\n","   30% blend + clear context: 96.7%\n","   50% blend + clear context: 56.1%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 5/10: 50%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 50% density...\n","   Pruning complete:\n","     fc1.weight: kept 512/1,024 weights (50.0% density)\n","     fc2.weight: kept 32,768/65,536 weights (50.0% density)\n","     fc3.weight: kept 16,384/32,768 weights (50.0% density)\n","     head.weight: kept 256/512 weights (50.0% density)\n","\n","   Mask Statistics (Target: 50%):\n","     fc1.weight: 512/1,024 active (50.0%)\n","     fc2.weight: 32,768/65,536 active (50.0%)\n","     fc3.weight: 16,384/32,768 active (50.0%)\n","     head.weight: 256/512 active (50.0%)\n","     TOTAL: 49,920/99,840 active (50.0%)\n","\n","   Training for 15 epochs at 50.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=50.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0003 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 50% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 50,564\n","   Density: 50.3%\n","   Sparsity: 49.7%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.6% (drop: +0.3%)\n","     Moderate (σ=1.0): 94.7% (drop: +5.3%)\n","         High (σ=2.0): 76.7% (drop: +23.3%)\n","       Severe (σ=3.0): 62.0% (drop: +37.9%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 100.0% (drop: +0.0%)\n","         Severe (w=0.55): 95.2% (drop: +4.8%)\n","      Ambiguous (w=0.50): 82.2% (drop: +17.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 50.6%\n","   30% blend + clear context: 96.9%\n","   50% blend + clear context: 54.5%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 6/10: 60%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 60% density...\n","   Pruning complete:\n","     fc1.weight: kept 614/1,024 weights (60.0% density)\n","     fc2.weight: kept 39,322/65,536 weights (60.0% density)\n","     fc3.weight: kept 19,661/32,768 weights (60.0% density)\n","     head.weight: kept 307/512 weights (60.0% density)\n","\n","   Mask Statistics (Target: 60%):\n","     fc1.weight: 614/1,024 active (60.0%)\n","     fc2.weight: 39,322/65,536 active (60.0%)\n","     fc3.weight: 19,661/32,768 active (60.0%)\n","     head.weight: 307/512 active (60.0%)\n","     TOTAL: 59,904/99,840 active (60.0%)\n","\n","   Training for 15 epochs at 60.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=60.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0003 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 60% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 60,548\n","   Density: 60.3%\n","   Sparsity: 39.7%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.9% (drop: +0.0%)\n","     Moderate (σ=1.0): 95.1% (drop: +4.8%)\n","         High (σ=2.0): 78.5% (drop: +21.4%)\n","       Severe (σ=3.0): 64.2% (drop: +35.8%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 91.4% (drop: +8.6%)\n","         Severe (w=0.55): 73.2% (drop: +26.8%)\n","      Ambiguous (w=0.50): 50.8% (drop: +49.2%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 40.3%\n","   30% blend + clear context: 97.1%\n","   50% blend + clear context: 56.2%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 7/10: 70%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 70% density...\n","   Pruning complete:\n","     fc1.weight: kept 717/1,024 weights (70.0% density)\n","     fc2.weight: kept 45,875/65,536 weights (70.0% density)\n","     fc3.weight: kept 22,937/32,768 weights (70.0% density)\n","     head.weight: kept 358/512 weights (69.9% density)\n","\n","   Mask Statistics (Target: 70%):\n","     fc1.weight: 717/1,024 active (70.0%)\n","     fc2.weight: 45,875/65,536 active (70.0%)\n","     fc3.weight: 22,937/32,768 active (70.0%)\n","     head.weight: 358/512 active (69.9%)\n","     TOTAL: 69,887/99,840 active (70.0%)\n","\n","   Training for 15 epochs at 70.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=70.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0005 Combined=0.0003 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 70% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 70,531\n","   Density: 70.2%\n","   Sparsity: 29.8%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 95.4% (drop: +4.6%)\n","         High (σ=2.0): 80.0% (drop: +20.0%)\n","       Severe (σ=3.0): 68.0% (drop: +31.9%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 99.5% (drop: +0.4%)\n","           High (w=0.60): 78.3% (drop: +21.6%)\n","         Severe (w=0.55): 75.3% (drop: +24.6%)\n","      Ambiguous (w=0.50): 49.1% (drop: +50.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 37.7%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 57.0%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 8/10: 80%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 80% density...\n","   Pruning complete:\n","     fc1.weight: kept 819/1,024 weights (80.0% density)\n","     fc2.weight: kept 52,429/65,536 weights (80.0% density)\n","     fc3.weight: kept 26,214/32,768 weights (80.0% density)\n","     head.weight: kept 409/512 weights (79.9% density)\n","\n","   Mask Statistics (Target: 80%):\n","     fc1.weight: 819/1,024 active (80.0%)\n","     fc2.weight: 52,429/65,536 active (80.0%)\n","     fc3.weight: 26,214/32,768 active (80.0%)\n","     head.weight: 409/512 active (79.9%)\n","     TOTAL: 79,871/99,840 active (80.0%)\n","\n","   Training for 15 epochs at 80.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=80.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0002 A=0.0007 Combined=0.0005 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0005\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 80% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 80,515\n","   Density: 80.1%\n","   Sparsity: 19.9%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.7% (drop: +0.2%)\n","     Moderate (σ=1.0): 96.2% (drop: +3.8%)\n","         High (σ=2.0): 81.9% (drop: +18.1%)\n","       Severe (σ=3.0): 68.1% (drop: +31.8%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 98.5% (drop: +1.5%)\n","           High (w=0.60): 62.3% (drop: +37.6%)\n","         Severe (w=0.55): 50.7% (drop: +49.3%)\n","      Ambiguous (w=0.50): 50.2% (drop: +49.7%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 38.5%\n","   30% blend + clear context: 96.4%\n","   50% blend + clear context: 54.8%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 9/10: 90%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 90% density...\n","   Pruning complete:\n","     fc1.weight: kept 921/1,024 weights (89.9% density)\n","     fc2.weight: kept 58,982/65,536 weights (90.0% density)\n","     fc3.weight: kept 29,491/32,768 weights (90.0% density)\n","     head.weight: kept 460/512 weights (89.8% density)\n","\n","   Mask Statistics (Target: 90%):\n","     fc1.weight: 921/1,024 active (89.9%)\n","     fc2.weight: 58,982/65,536 active (90.0%)\n","     fc3.weight: 29,491/32,768 active (90.0%)\n","     head.weight: 460/512 active (89.8%)\n","     TOTAL: 89,854/99,840 active (90.0%)\n","\n","   Training for 15 epochs at 90.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=90.0%)\n","\n","    Epoch   5/15: Loss V=0.0003 A=0.0004 Combined=0.0004 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=99.9% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 99.9%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 90% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 90,498\n","   Density: 90.1%\n","   Sparsity: 9.9%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 99.9%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 100.0% (drop: -0.1%)\n","     Moderate (σ=1.0): 97.6% (drop: +2.3%)\n","         High (σ=2.0): 84.7% (drop: +15.2%)\n","       Severe (σ=3.0): 70.2% (drop: +29.7%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 99.9%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.0%)\n","           High (w=0.60): 93.3% (drop: +6.6%)\n","         Severe (w=0.55): 80.2% (drop: +19.7%)\n","      Ambiguous (w=0.50): 75.8% (drop: +24.2%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 48.6%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.8%\n","\n","   State saved for late stage experiments.\n","\n","----------------------------------------------------------------------\n"," EARLY STAGE - Density Level 10/10: 100%\n","----------------------------------------------------------------------\n","\n","   Loading baseline state...\n","   Pruning to 100% density...\n","   Pruning complete:\n","     fc1.weight: kept 1,024/1,024 weights (100.0% density)\n","     fc2.weight: kept 65,536/65,536 weights (100.0% density)\n","     fc3.weight: kept 32,768/32,768 weights (100.0% density)\n","     head.weight: kept 512/512 weights (100.0% density)\n","\n","   Mask Statistics (Target: 100%):\n","     fc1.weight: 1,024/1,024 active (100.0%)\n","     fc2.weight: 65,536/65,536 active (100.0%)\n","     fc3.weight: 32,768/32,768 active (100.0%)\n","     head.weight: 512/512 active (100.0%)\n","     TOTAL: 99,840/99,840 active (100.0%)\n","\n","   Training for 15 epochs at 100.0% density...\n","\n","   Training Configuration:\n","     - Epochs: 15\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=100.0%)\n","\n","    Epoch   5/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/15: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  15/15: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: EARLY STAGE - 100% Density\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 100,484\n","   Density: 100.0%\n","   Sparsity: 0.0%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.9% (drop: +0.0%)\n","     Moderate (σ=1.0): 97.5% (drop: +2.4%)\n","         High (σ=2.0): 83.7% (drop: +16.3%)\n","       Severe (σ=3.0): 68.8% (drop: +31.2%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.0%)\n","           High (w=0.60): 98.2% (drop: +1.8%)\n","         Severe (w=0.55): 77.7% (drop: +22.3%)\n","      Ambiguous (w=0.50): 53.2% (drop: +46.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 43.1%\n","   30% blend + clear context: 97.2%\n","   50% blend + clear context: 56.9%\n","\n","   State saved for late stage experiments.\n","\n","======================================================================\n"," EARLY STAGE SUMMARY TABLE\n","======================================================================\n","\n","    Density     Visual      Voice    Stress Hi    Ambiguous  Blend+Ambig\n"," ---------------------------------------------------------------------------\n","      10.0%     100.0%      50.0%        45.0%       100.0%        56.5%\n","      20.0%     100.0%     100.0%        53.5%        69.3%        46.9%\n","      30.0%     100.0%     100.0%        66.1%        75.2%        47.0%\n","      40.0%     100.0%     100.0%        72.8%        75.5%        48.5%\n","      50.0%     100.0%     100.0%        76.7%        82.2%        50.6%\n","      60.0%     100.0%     100.0%        78.5%        50.8%        40.3%\n","      70.0%     100.0%     100.0%        80.0%        49.1%        37.7%\n","      80.0%     100.0%     100.0%        81.9%        50.2%        38.5%\n","      90.0%      99.9%     100.0%        84.7%        75.8%        48.6%\n","     100.0%     100.0%     100.0%        83.7%        53.2%        43.1%\n","\n","================================================================================\n"," LATE STAGE: DIFFERENTIAL PRUNING (Normal vs ASD)\n","================================================================================\n","\n"," For each early density state, we now apply additional late-stage pruning:\n","   - Normal condition: Remove 20% of remaining weights\n","   - ASD condition: Remove 50% of remaining weights\n","\n"," This models developmental scenarios where:\n","   - Normal development has moderate synaptic pruning during adolescence\n","   - ASD may have insufficient pruning (this experiment tests EXCESSIVE pruning as comparison)\n","    \n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 10% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 50.0%\n","     Stress tolerance (high): 45.0%\n","     Ambiguity tolerance: 100.0%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (10% density)...\n","   Pre-pruning density: 10.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 21 weights, 82 remaining (20.4% removed)\n","     fc2.weight: removed 1,311 weights, 5,243 remaining (20.0% removed)\n","     fc3.weight: removed 656 weights, 2,621 remaining (20.0% removed)\n","     head.weight: removed 11 weights, 41 remaining (21.2% removed)\n","   Post-pruning density: 8.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=8.0%)\n","\n","    Epoch   5/10: Loss V=0.0008 A=0.6956 Combined=0.3482 | Acc V=100.0% A=49.9%\n","    Epoch  10/10: Loss V=0.0003 A=0.6949 Combined=0.3476 | Acc V=100.0% A=50.1%\n","\n","   Training Complete:\n","     - Final combined loss: 0.3476\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 50.1%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 10% → 8.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 8,631\n","   Density: 8.6%\n","   Sparsity: 91.4%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 50.1%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 94.6% (drop: +5.4%)\n","     Moderate (σ=1.0): 72.9% (drop: +27.1%)\n","         High (σ=2.0): 48.8% (drop: +51.2%)\n","       Severe (σ=3.0): 40.2% (drop: +59.8%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 100.0% (drop: +0.0%)\n","         Severe (w=0.55): 100.0% (drop: +0.0%)\n","      Ambiguous (w=0.50): 100.0% (drop: +0.0%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 56.2%\n","   30% blend + clear context: 97.1%\n","   50% blend + clear context: 57.4%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (10% density)...\n","   Pre-pruning density: 10.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 51 weights, 52 remaining (49.5% removed)\n","     fc2.weight: removed 3,277 weights, 3,277 remaining (50.0% removed)\n","     fc3.weight: removed 1,638 weights, 1,639 remaining (50.0% removed)\n","     head.weight: removed 26 weights, 26 remaining (50.0% removed)\n","   Post-pruning density: 5.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=5.0%)\n","\n","    Epoch   5/10: Loss V=0.0032 A=0.6967 Combined=0.3499 | Acc V=100.0% A=49.8%\n","    Epoch  10/10: Loss V=0.0010 A=0.6946 Combined=0.3478 | Acc V=100.0% A=50.1%\n","\n","   Training Complete:\n","     - Final combined loss: 0.3478\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 50.1%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 10% → 5.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 5,638\n","   Density: 5.6%\n","   Sparsity: 94.4%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 50.1%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 95.6% (drop: +4.3%)\n","     Moderate (σ=1.0): 74.7% (drop: +25.3%)\n","         High (σ=2.0): 52.9% (drop: +47.0%)\n","       Severe (σ=3.0): 41.7% (drop: +58.3%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 100.0% (drop: +0.0%)\n","         Severe (w=0.55): 99.9% (drop: +0.0%)\n","      Ambiguous (w=0.50): 99.9% (drop: +0.0%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 55.8%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.0%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 10% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                     8.0%         5.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                   50.1%        50.1%        -0.0%\n","   Stress Tolerance (high)          48.8%        52.9%        -4.2%\n","   Ambiguity Tolerance             100.0%        99.9%        +0.0%\n","   Blend + Ambiguity                56.2%        55.8%        +0.5%\n","\n","   Interpretation:\n","     → Normal and ASD perform equally on visual task\n","     → ASD has better stress tolerance by 4.2%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 20% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 53.5%\n","     Ambiguity tolerance: 69.3%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (20% density)...\n","   Pre-pruning density: 20.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 41 weights, 164 remaining (20.0% removed)\n","     fc2.weight: removed 2,622 weights, 10,486 remaining (20.0% removed)\n","     fc3.weight: removed 1,311 weights, 5,243 remaining (20.0% removed)\n","     head.weight: removed 21 weights, 82 remaining (20.4% removed)\n","   Post-pruning density: 16.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=16.0%)\n","\n","    Epoch   5/10: Loss V=0.0001 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 20% → 16.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 16,619\n","   Density: 16.5%\n","   Sparsity: 83.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 97.2% (drop: +2.8%)\n","     Moderate (σ=1.0): 79.7% (drop: +20.3%)\n","         High (σ=2.0): 54.6% (drop: +45.3%)\n","       Severe (σ=3.0): 44.6% (drop: +55.4%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 98.7% (drop: +1.3%)\n","         Severe (w=0.55): 81.3% (drop: +18.6%)\n","      Ambiguous (w=0.50): 71.8% (drop: +28.2%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 47.0%\n","   30% blend + clear context: 97.4%\n","   50% blend + clear context: 55.7%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (20% density)...\n","   Pre-pruning density: 20.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 102 weights, 103 remaining (49.8% removed)\n","     fc2.weight: removed 6,554 weights, 6,554 remaining (50.0% removed)\n","     fc3.weight: removed 3,277 weights, 3,277 remaining (50.0% removed)\n","     head.weight: removed 51 weights, 52 remaining (49.5% removed)\n","   Post-pruning density: 10.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=10.0%)\n","\n","    Epoch   5/10: Loss V=0.0028 A=0.0009 Combined=0.0018 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0007 A=0.0003 Combined=0.0005 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0005\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 20% → 10.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 10,630\n","   Density: 10.6%\n","   Sparsity: 89.4%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 88.3% (drop: +11.6%)\n","     Moderate (σ=1.0): 65.4% (drop: +34.6%)\n","         High (σ=2.0): 45.1% (drop: +54.8%)\n","       Severe (σ=3.0): 36.6% (drop: +63.4%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 99.1% (drop: +0.9%)\n","         Severe (w=0.55): 76.5% (drop: +23.5%)\n","      Ambiguous (w=0.50): 58.7% (drop: +41.3%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 41.1%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.6%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 20% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    16.0%        10.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        -0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          54.6%        45.1%        +9.5%\n","   Ambiguity Tolerance              71.8%        58.7%       +13.1%\n","   Blend + Ambiguity                47.0%        41.1%        +5.9%\n","\n","   Interpretation:\n","     → ASD outperforms Normal by 0.0% on visual task\n","     → Normal has better stress tolerance by 9.5%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 30% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 66.1%\n","     Ambiguity tolerance: 75.2%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (30% density)...\n","   Pre-pruning density: 30.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 62 weights, 245 remaining (20.2% removed)\n","     fc2.weight: removed 3,932 weights, 15,729 remaining (20.0% removed)\n","     fc3.weight: removed 1,966 weights, 7,865 remaining (20.0% removed)\n","     head.weight: removed 31 weights, 123 remaining (20.1% removed)\n","   Post-pruning density: 24.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=24.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0001 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 30% → 24.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 24,606\n","   Density: 24.5%\n","   Sparsity: 75.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 98.4% (drop: +1.5%)\n","     Moderate (σ=1.0): 85.6% (drop: +14.4%)\n","         High (σ=2.0): 62.9% (drop: +37.1%)\n","       Severe (σ=3.0): 49.6% (drop: +50.3%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 98.7% (drop: +1.2%)\n","         Severe (w=0.55): 90.3% (drop: +9.7%)\n","      Ambiguous (w=0.50): 46.9% (drop: +53.1%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 42.3%\n","   30% blend + clear context: 97.2%\n","   50% blend + clear context: 55.2%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (30% density)...\n","   Pre-pruning density: 30.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 153 weights, 154 remaining (49.8% removed)\n","     fc2.weight: removed 9,830 weights, 9,831 remaining (50.0% removed)\n","     fc3.weight: removed 4,915 weights, 4,916 remaining (50.0% removed)\n","     head.weight: removed 77 weights, 77 remaining (50.0% removed)\n","   Post-pruning density: 15.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=15.0%)\n","\n","    Epoch   5/10: Loss V=0.0007 A=0.0007 Combined=0.0007 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0002 A=0.0003 Combined=0.0002 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0002\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 30% → 15.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 15,622\n","   Density: 15.5%\n","   Sparsity: 84.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 92.5% (drop: +7.5%)\n","     Moderate (σ=1.0): 67.3% (drop: +32.7%)\n","         High (σ=2.0): 43.8% (drop: +56.2%)\n","       Severe (σ=3.0): 36.0% (drop: +64.0%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 99.9% (drop: +0.0%)\n","         Severe (w=0.55): 92.9% (drop: +7.0%)\n","      Ambiguous (w=0.50): 38.5% (drop: +61.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 39.3%\n","   30% blend + clear context: 97.3%\n","   50% blend + clear context: 57.0%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 30% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    24.0%        15.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        -0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          62.9%        43.8%       +19.1%\n","   Ambiguity Tolerance              46.9%        38.5%        +8.4%\n","   Blend + Ambiguity                42.3%        39.3%        +3.0%\n","\n","   Interpretation:\n","     → ASD outperforms Normal by 0.0% on visual task\n","     → Normal has better stress tolerance by 19.1%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 40% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 72.8%\n","     Ambiguity tolerance: 75.5%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (40% density)...\n","   Pre-pruning density: 40.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 82 weights, 328 remaining (20.0% removed)\n","     fc2.weight: removed 5,243 weights, 20,972 remaining (20.0% removed)\n","     fc3.weight: removed 2,622 weights, 10,485 remaining (20.0% removed)\n","     head.weight: removed 41 weights, 164 remaining (20.0% removed)\n","   Post-pruning density: 32.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=32.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0004 Combined=0.0002 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 40% → 32.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 32,593\n","   Density: 32.4%\n","   Sparsity: 67.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.5% (drop: +0.4%)\n","     Moderate (σ=1.0): 91.3% (drop: +8.7%)\n","         High (σ=2.0): 69.2% (drop: +30.8%)\n","       Severe (σ=3.0): 56.6% (drop: +43.4%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.0%)\n","           High (w=0.60): 99.4% (drop: +0.5%)\n","         Severe (w=0.55): 96.3% (drop: +3.7%)\n","      Ambiguous (w=0.50): 88.5% (drop: +11.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 53.7%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.2%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (40% density)...\n","   Pre-pruning density: 40.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 205 weights, 205 remaining (50.0% removed)\n","     fc2.weight: removed 13,107 weights, 13,108 remaining (50.0% removed)\n","     fc3.weight: removed 6,553 weights, 6,554 remaining (50.0% removed)\n","     head.weight: removed 102 weights, 103 remaining (49.8% removed)\n","   Post-pruning density: 20.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=20.0%)\n","\n","    Epoch   5/10: Loss V=0.0001 A=0.0003 Combined=0.0002 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 40% → 20.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 20,614\n","   Density: 20.5%\n","   Sparsity: 79.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 96.5% (drop: +3.5%)\n","     Moderate (σ=1.0): 75.7% (drop: +24.3%)\n","         High (σ=2.0): 53.4% (drop: +46.6%)\n","       Severe (σ=3.0): 46.4% (drop: +53.6%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 97.3% (drop: +2.7%)\n","         Severe (w=0.55): 79.7% (drop: +20.3%)\n","      Ambiguous (w=0.50): 33.3% (drop: +66.7%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 36.0%\n","   30% blend + clear context: 97.5%\n","   50% blend + clear context: 55.9%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 40% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    32.0%        20.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        -0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          69.2%        53.4%       +15.9%\n","   Ambiguity Tolerance              88.5%        33.3%       +55.2%\n","   Blend + Ambiguity                53.7%        36.0%       +17.7%\n","\n","   Interpretation:\n","     → ASD outperforms Normal by 0.0% on visual task\n","     → Normal has better stress tolerance by 15.9%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 50% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 76.7%\n","     Ambiguity tolerance: 82.2%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (50% density)...\n","   Pre-pruning density: 50.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 103 weights, 409 remaining (20.1% removed)\n","     fc2.weight: removed 6,554 weights, 26,214 remaining (20.0% removed)\n","     fc3.weight: removed 3,277 weights, 13,107 remaining (20.0% removed)\n","     head.weight: removed 51 weights, 205 remaining (19.9% removed)\n","   Post-pruning density: 40.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=40.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 50% → 40.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 40,579\n","   Density: 40.4%\n","   Sparsity: 59.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.4% (drop: +0.5%)\n","     Moderate (σ=1.0): 92.5% (drop: +7.5%)\n","         High (σ=2.0): 71.5% (drop: +28.5%)\n","       Severe (σ=3.0): 59.4% (drop: +40.5%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 98.8% (drop: +1.2%)\n","         Severe (w=0.55): 94.3% (drop: +5.7%)\n","      Ambiguous (w=0.50): 77.6% (drop: +22.4%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 52.4%\n","   30% blend + clear context: 96.6%\n","   50% blend + clear context: 54.4%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (50% density)...\n","   Pre-pruning density: 50.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 256 weights, 256 remaining (50.0% removed)\n","     fc2.weight: removed 16,384 weights, 16,384 remaining (50.0% removed)\n","     fc3.weight: removed 8,192 weights, 8,192 remaining (50.0% removed)\n","     head.weight: removed 128 weights, 128 remaining (50.0% removed)\n","   Post-pruning density: 25.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=25.0%)\n","\n","    Epoch   5/10: Loss V=0.0001 A=0.0002 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 50% → 25.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 25,604\n","   Density: 25.5%\n","   Sparsity: 74.5%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 97.4% (drop: +2.6%)\n","     Moderate (σ=1.0): 81.8% (drop: +18.2%)\n","         High (σ=2.0): 58.7% (drop: +41.2%)\n","       Severe (σ=3.0): 48.8% (drop: +51.2%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 95.7% (drop: +4.2%)\n","         Severe (w=0.55): 76.1% (drop: +23.8%)\n","      Ambiguous (w=0.50): 41.5% (drop: +58.4%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 40.2%\n","   30% blend + clear context: 96.9%\n","   50% blend + clear context: 56.4%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 50% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    40.0%        25.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          71.5%        58.7%       +12.8%\n","   Ambiguity Tolerance              77.6%        41.5%       +36.1%\n","   Blend + Ambiguity                52.4%        40.2%       +12.1%\n","\n","   Interpretation:\n","     → Normal and ASD perform equally on visual task\n","     → Normal has better stress tolerance by 12.8%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 60% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 78.5%\n","     Ambiguity tolerance: 50.8%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (60% density)...\n","   Pre-pruning density: 60.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 123 weights, 491 remaining (20.0% removed)\n","     fc2.weight: removed 7,865 weights, 31,457 remaining (20.0% removed)\n","     fc3.weight: removed 3,932 weights, 15,729 remaining (20.0% removed)\n","     head.weight: removed 62 weights, 245 remaining (20.2% removed)\n","   Post-pruning density: 48.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=48.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0004 Combined=0.0002 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 60% → 48.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 48,566\n","   Density: 48.3%\n","   Sparsity: 51.7%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.7% (drop: +0.3%)\n","     Moderate (σ=1.0): 92.8% (drop: +7.2%)\n","         High (σ=2.0): 71.4% (drop: +28.5%)\n","       Severe (σ=3.0): 59.5% (drop: +40.4%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 99.6% (drop: +0.4%)\n","         Severe (w=0.55): 89.2% (drop: +10.7%)\n","      Ambiguous (w=0.50): 64.1% (drop: +35.9%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 45.5%\n","   30% blend + clear context: 97.0%\n","   50% blend + clear context: 55.4%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (60% density)...\n","   Pre-pruning density: 60.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 307 weights, 307 remaining (50.0% removed)\n","     fc2.weight: removed 19,661 weights, 19,661 remaining (50.0% removed)\n","     fc3.weight: removed 9,830 weights, 9,831 remaining (50.0% removed)\n","     head.weight: removed 153 weights, 154 remaining (49.8% removed)\n","   Post-pruning density: 30.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=30.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 60% → 30.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 30,597\n","   Density: 30.4%\n","   Sparsity: 69.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.1% (drop: +0.9%)\n","     Moderate (σ=1.0): 86.7% (drop: +13.3%)\n","         High (σ=2.0): 62.9% (drop: +37.1%)\n","       Severe (σ=3.0): 51.5% (drop: +48.5%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 99.5% (drop: +0.5%)\n","         Severe (w=0.55): 96.9% (drop: +3.0%)\n","      Ambiguous (w=0.50): 85.5% (drop: +14.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 52.8%\n","   30% blend + clear context: 96.9%\n","   50% blend + clear context: 57.5%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 60% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    48.0%        30.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          71.4%        62.9%        +8.5%\n","   Ambiguity Tolerance              64.1%        85.5%       -21.4%\n","   Blend + Ambiguity                45.5%        52.8%        -7.3%\n","\n","   Interpretation:\n","     → Normal and ASD perform equally on visual task\n","     → Normal has better stress tolerance by 8.5%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 70% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 80.0%\n","     Ambiguity tolerance: 49.1%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (70% density)...\n","   Pre-pruning density: 70.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 144 weights, 573 remaining (20.1% removed)\n","     fc2.weight: removed 9,175 weights, 36,700 remaining (20.0% removed)\n","     fc3.weight: removed 4,588 weights, 18,349 remaining (20.0% removed)\n","     head.weight: removed 72 weights, 286 remaining (20.1% removed)\n","   Post-pruning density: 56.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=56.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0003 Combined=0.0002 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 70% → 56.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 56,552\n","   Density: 56.3%\n","   Sparsity: 43.7%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 95.6% (drop: +4.3%)\n","         High (σ=2.0): 77.9% (drop: +22.1%)\n","       Severe (σ=3.0): 63.9% (drop: +36.1%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 100.0% (drop: +0.0%)\n","           High (w=0.60): 99.5% (drop: +0.5%)\n","         Severe (w=0.55): 92.3% (drop: +7.7%)\n","      Ambiguous (w=0.50): 63.8% (drop: +36.1%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 45.9%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.4%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (70% density)...\n","   Pre-pruning density: 70.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 358 weights, 359 remaining (49.9% removed)\n","     fc2.weight: removed 22,937 weights, 22,938 remaining (50.0% removed)\n","     fc3.weight: removed 11,468 weights, 11,469 remaining (50.0% removed)\n","     head.weight: removed 179 weights, 179 remaining (50.0% removed)\n","   Post-pruning density: 35.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=35.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 70% → 35.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 35,589\n","   Density: 35.4%\n","   Sparsity: 64.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 98.6% (drop: +1.3%)\n","     Moderate (σ=1.0): 87.2% (drop: +12.8%)\n","         High (σ=2.0): 65.8% (drop: +34.1%)\n","       Severe (σ=3.0): 54.4% (drop: +45.5%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 98.5% (drop: +1.4%)\n","         Severe (w=0.55): 89.2% (drop: +10.8%)\n","      Ambiguous (w=0.50): 51.9% (drop: +48.1%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 42.1%\n","   30% blend + clear context: 97.1%\n","   50% blend + clear context: 56.5%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 70% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    56.0%        35.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          77.9%        65.8%       +12.1%\n","   Ambiguity Tolerance              63.8%        51.9%       +11.9%\n","   Blend + Ambiguity                45.9%        42.1%        +3.8%\n","\n","   Interpretation:\n","     → Normal outperforms ASD by 0.0% on visual task\n","     → Normal has better stress tolerance by 12.1%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 80% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 81.9%\n","     Ambiguity tolerance: 50.2%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (80% density)...\n","   Pre-pruning density: 80.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 164 weights, 655 remaining (20.0% removed)\n","     fc2.weight: removed 10,486 weights, 41,943 remaining (20.0% removed)\n","     fc3.weight: removed 5,243 weights, 20,971 remaining (20.0% removed)\n","     head.weight: removed 82 weights, 327 remaining (20.0% removed)\n","   Post-pruning density: 64.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=64.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 80% → 64.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 64,540\n","   Density: 64.2%\n","   Sparsity: 35.8%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 94.7% (drop: +5.3%)\n","         High (σ=2.0): 78.8% (drop: +21.1%)\n","       Severe (σ=3.0): 65.8% (drop: +34.1%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: +0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.1%)\n","           High (w=0.60): 94.7% (drop: +5.3%)\n","         Severe (w=0.55): 61.6% (drop: +38.4%)\n","      Ambiguous (w=0.50): 48.2% (drop: +51.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 40.8%\n","   30% blend + clear context: 97.3%\n","   50% blend + clear context: 57.3%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (80% density)...\n","   Pre-pruning density: 80.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 409 weights, 410 remaining (49.9% removed)\n","     fc2.weight: removed 26,214 weights, 26,215 remaining (50.0% removed)\n","     fc3.weight: removed 13,107 weights, 13,107 remaining (50.0% removed)\n","     head.weight: removed 204 weights, 205 remaining (49.9% removed)\n","   Post-pruning density: 40.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=40.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 80% → 40.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 40,581\n","   Density: 40.4%\n","   Sparsity: 59.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 98.5% (drop: +1.5%)\n","     Moderate (σ=1.0): 87.8% (drop: +12.2%)\n","         High (σ=2.0): 67.0% (drop: +33.0%)\n","       Severe (σ=3.0): 56.1% (drop: +43.9%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 95.4% (drop: +4.6%)\n","         Severe (w=0.55): 59.7% (drop: +40.2%)\n","      Ambiguous (w=0.50): 46.5% (drop: +53.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 39.9%\n","   30% blend + clear context: 96.4%\n","   50% blend + clear context: 54.6%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 80% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    64.0%        40.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          78.8%        67.0%       +11.8%\n","   Ambiguity Tolerance              48.2%        46.5%        +1.7%\n","   Blend + Ambiguity                40.8%        39.9%        +1.0%\n","\n","   Interpretation:\n","     → Normal outperforms ASD by 0.0% on visual task\n","     → Normal has better stress tolerance by 11.8%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 90% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 99.9%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 84.7%\n","     Ambiguity tolerance: 75.8%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (90% density)...\n","   Pre-pruning density: 90.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 184 weights, 737 remaining (20.0% removed)\n","     fc2.weight: removed 11,797 weights, 47,185 remaining (20.0% removed)\n","     fc3.weight: removed 5,898 weights, 23,593 remaining (20.0% removed)\n","     head.weight: removed 92 weights, 368 remaining (20.0% removed)\n","   Post-pruning density: 72.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=72.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=99.9% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 90% → 72.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 72,527\n","   Density: 72.2%\n","   Sparsity: 27.8%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 96.0% (drop: +3.9%)\n","         High (σ=2.0): 78.3% (drop: +21.6%)\n","       Severe (σ=3.0): 64.7% (drop: +35.3%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 99.9% (drop: +0.1%)\n","           High (w=0.60): 77.2% (drop: +22.7%)\n","         Severe (w=0.55): 38.6% (drop: +61.3%)\n","      Ambiguous (w=0.50): 6.8% (drop: +93.2%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 29.5%\n","   30% blend + clear context: 97.3%\n","   50% blend + clear context: 56.7%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (90% density)...\n","   Pre-pruning density: 90.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 460 weights, 461 remaining (49.9% removed)\n","     fc2.weight: removed 29,491 weights, 29,491 remaining (50.0% removed)\n","     fc3.weight: removed 14,745 weights, 14,746 remaining (50.0% removed)\n","     head.weight: removed 230 weights, 230 remaining (50.0% removed)\n","   Post-pruning density: 45.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=45.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0001 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0001\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 90% → 45.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 45,572\n","   Density: 45.4%\n","   Sparsity: 54.6%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.7% (drop: +0.2%)\n","     Moderate (σ=1.0): 93.9% (drop: +6.0%)\n","         High (σ=2.0): 73.7% (drop: +26.3%)\n","       Severe (σ=3.0): 62.8% (drop: +37.1%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 99.3% (drop: +0.7%)\n","         Severe (w=0.55): 92.8% (drop: +7.2%)\n","      Ambiguous (w=0.50): 80.1% (drop: +19.8%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 51.2%\n","   30% blend + clear context: 96.4%\n","   50% blend + clear context: 56.8%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 90% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    72.0%        45.0%          ---\n","   Visual Accuracy                 100.0%       100.0%        +0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          78.3%        73.7%        +4.7%\n","   Ambiguity Tolerance               6.8%        80.1%       -73.3%\n","   Blend + Ambiguity                29.5%        51.2%       -21.7%\n","\n","   Interpretation:\n","     → Normal and ASD perform equally on visual task\n","     → Normal has better stress tolerance by 4.7%\n","\n","======================================================================\n"," LATE STAGE: Starting from EARLY 100% Density\n","======================================================================\n","\n","   Early stage baseline performance:\n","     Visual accuracy: 100.0%\n","     Voice accuracy: 100.0%\n","     Stress tolerance (high): 83.7%\n","     Ambiguity tolerance: 53.2%\n","\n","------------------------------------------------------------\n","   NORMAL CONDITION: Remove 20% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (100% density)...\n","   Pre-pruning density: 100.0%\n","   Applying 20% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 205 weights, 819 remaining (20.0% removed)\n","     fc2.weight: removed 13,107 weights, 52,429 remaining (20.0% removed)\n","     fc3.weight: removed 6,554 weights, 26,214 remaining (20.0% removed)\n","     head.weight: removed 103 weights, 409 remaining (20.1% removed)\n","   Post-pruning density: 80.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=80.0%)\n","\n","    Epoch   5/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0000 Combined=0.0000 | Acc V=99.9% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 99.9%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE NORMAL (from 100% → 80.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 80,515\n","   Density: 80.1%\n","   Sparsity: 19.9%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 99.9%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.8% (drop: +0.1%)\n","     Moderate (σ=1.0): 96.0% (drop: +3.9%)\n","         High (σ=2.0): 80.3% (drop: +19.6%)\n","       Severe (σ=3.0): 64.8% (drop: +35.2%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 99.9%\n","         Slight (w=0.85): 99.9% (drop: +0.0%)\n","       Moderate (w=0.70): 98.2% (drop: +1.8%)\n","           High (w=0.60): 78.4% (drop: +21.5%)\n","         Severe (w=0.55): 63.1% (drop: +36.8%)\n","      Ambiguous (w=0.50): 49.4% (drop: +50.5%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 38.0%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 56.5%\n","\n","------------------------------------------------------------\n","   ASD CONDITION: Remove 50% of remaining weights\n","------------------------------------------------------------\n","\n","   Loading early state (100% density)...\n","   Pre-pruning density: 100.0%\n","   Applying 50% additional pruning...\n","   Pruning details:\n","     fc1.weight: removed 512 weights, 512 remaining (50.0% removed)\n","     fc2.weight: removed 32,768 weights, 32,768 remaining (50.0% removed)\n","     fc3.weight: removed 16,384 weights, 16,384 remaining (50.0% removed)\n","     head.weight: removed 256 weights, 256 remaining (50.0% removed)\n","   Post-pruning density: 50.0%\n","\n","   Fine-tuning for 10 epochs...\n","\n","   Training Configuration:\n","     - Epochs: 10\n","     - Learning rate: 0.0005\n","     - Optimizer: Adam\n","     - Loss function: CrossEntropyLoss\n","     - Pruning manager: Active (density=50.0%)\n","\n","    Epoch   5/10: Loss V=0.0001 A=0.0000 Combined=0.0000 | Acc V=100.0% A=100.0%\n","    Epoch  10/10: Loss V=0.0000 A=0.0001 Combined=0.0000 | Acc V=100.0% A=100.0%\n","\n","   Training Complete:\n","     - Final combined loss: 0.0000\n","     - Final visual accuracy: 100.0%\n","     - Final voice accuracy: 100.0%\n","\n","======================================================================\n"," EVALUATION: LATE ASD (from 100% → 50.0%)\n","======================================================================\n","\n"," Network Statistics:\n","   Total parameters: 100,484\n","   Non-zero parameters: 50,564\n","   Density: 50.3%\n","   Sparsity: 49.7%\n","\n"," Basic Task Performance:\n","   Visual task accuracy: 100.0%\n","   Voice task accuracy: 100.0%\n","\n"," Stress Tolerance (Visual Task):\n","         Mild (σ=0.5): 99.7% (drop: +0.3%)\n","     Moderate (σ=1.0): 93.7% (drop: +6.3%)\n","         High (σ=2.0): 75.5% (drop: +24.5%)\n","       Severe (σ=3.0): 62.0% (drop: +38.0%)\n","\n"," Ambiguity Tolerance (Visual Task):\n","    Pure_visual (w=1.00): 100.0%\n","         Slight (w=0.85): 100.0% (drop: -0.0%)\n","       Moderate (w=0.70): 100.0% (drop: -0.0%)\n","           High (w=0.60): 99.5% (drop: +0.4%)\n","         Severe (w=0.55): 94.5% (drop: +5.5%)\n","      Ambiguous (w=0.50): 75.1% (drop: +24.9%)\n","\n"," Blended Input Tests:\n","   50% blend + ambiguous context: 50.3%\n","   30% blend + clear context: 96.8%\n","   50% blend + clear context: 55.8%\n","\n","------------------------------------------------------------\n","   COMPARISON: Normal vs ASD (from 100% early density)\n","------------------------------------------------------------\n","\n","   Metric                          Normal          ASD   Diff (N-A)\n","   -----------------------------------------------------------------\n","   Final Density                    80.0%        50.0%          ---\n","   Visual Accuracy                  99.9%       100.0%        -0.0%\n","   Voice Accuracy                  100.0%       100.0%        +0.0%\n","   Stress Tolerance (high)          80.3%        75.5%        +4.8%\n","   Ambiguity Tolerance              49.4%        75.1%       -25.7%\n","   Blend + Ambiguity                38.0%        50.3%       -12.4%\n","\n","   Interpretation:\n","     → ASD outperforms Normal by 0.0% on visual task\n","     → Normal has better stress tolerance by 4.8%\n","\n","================================================================================\n"," COMPREHENSIVE SUMMARY TABLES\n","================================================================================\n","\n","----------------------------------------------------------------------\n"," TABLE 1: EARLY STAGE RESULTS (Density Sweep)\n","----------------------------------------------------------------------\n","\n","    Density     Visual      Voice    Stress Hi    Ambiguous  Blend+Ambig\n"," ---------------------------------------------------------------------------\n","      10.0%     100.0%      50.0%        45.0%       100.0%        56.5%\n","      20.0%     100.0%     100.0%        53.5%        69.3%        46.9%\n","      30.0%     100.0%     100.0%        66.1%        75.2%        47.0%\n","      40.0%     100.0%     100.0%        72.8%        75.5%        48.5%\n","      50.0%     100.0%     100.0%        76.7%        82.2%        50.6%\n","      60.0%     100.0%     100.0%        78.5%        50.8%        40.3%\n","      70.0%     100.0%     100.0%        80.0%        49.1%        37.7%\n","      80.0%     100.0%     100.0%        81.9%        50.2%        38.5%\n","      90.0%      99.9%     100.0%        84.7%        75.8%        48.6%\n","     100.0%     100.0%     100.0%        83.7%        53.2%        43.1%\n","\n","----------------------------------------------------------------------\n"," TABLE 2: LATE STAGE COMPARISON (Normal vs ASD)\n","----------------------------------------------------------------------\n","\n"," Normal: 20% pruned | ASD: 50% pruned\n","\n","   Early%   N-Dens   A-Dens    N-Vis    A-Vis     Diff    N-Str    A-Str     Diff\n"," -------------------------------------------------------------------------------------\n","      10%     8.0%     5.0%   100.0%   100.0%    +0.0%    48.8%    52.9%    -4.2%\n","      20%    16.0%    10.0%   100.0%   100.0%    -0.0%    54.6%    45.1%    +9.5%\n","      30%    24.0%    15.0%   100.0%   100.0%    -0.0%    62.9%    43.8%   +19.1%\n","      40%    32.0%    20.0%   100.0%   100.0%    -0.0%    69.2%    53.4%   +15.9%\n","      50%    40.0%    25.0%   100.0%   100.0%    +0.0%    71.5%    58.7%   +12.8%\n","      60%    48.0%    30.0%   100.0%   100.0%    +0.0%    71.4%    62.9%    +8.5%\n","      70%    56.0%    35.0%   100.0%   100.0%    +0.0%    77.9%    65.8%   +12.1%\n","      80%    64.0%    40.0%   100.0%   100.0%    +0.0%    78.8%    67.0%   +11.8%\n","      90%    72.0%    45.0%   100.0%   100.0%    +0.0%    78.3%    73.7%    +4.7%\n","     100%    80.0%    50.0%    99.9%   100.0%    -0.0%    80.3%    75.5%    +4.8%\n","\n","----------------------------------------------------------------------\n"," TABLE 3: EARLY → LATE PROGRESSION\n","----------------------------------------------------------------------\n","\n","   Early%  Early-Vis      N-Vis      A-Vis      E→N Δ      E→A Δ\n"," -----------------------------------------------------------------\n","      10%     100.0%     100.0%     100.0%      +0.0%      +0.0%\n","      20%     100.0%     100.0%     100.0%      -0.0%      +0.0%\n","      30%     100.0%     100.0%     100.0%      -0.0%      +0.0%\n","      40%     100.0%     100.0%     100.0%      -0.0%      +0.0%\n","      50%     100.0%     100.0%     100.0%      -0.0%      -0.0%\n","      60%     100.0%     100.0%     100.0%      +0.0%      +0.0%\n","      70%     100.0%     100.0%     100.0%      +0.0%      -0.0%\n","      80%     100.0%     100.0%     100.0%      +0.0%      -0.0%\n","      90%      99.9%     100.0%     100.0%      +0.0%      +0.0%\n","     100%     100.0%      99.9%     100.0%      -0.0%      +0.0%\n","\n","================================================================================\n"," DETAILED ANALYSIS\n","================================================================================\n","\n"," EARLY STAGE FINDINGS:\n"," =====================\n","\n"," Optimal Early Density:\n","   - Best visual accuracy: 100.0% at 20% density\n","   - This suggests that moderate pruning may help, but excessive pruning hurts\n","\n"," Density-Performance Relationship:\n","   - Lower densities (10-30%): Likely degraded performance due to insufficient capacity\n","   - Moderate densities (40-70%): May achieve good balance\n","   - High densities (80-100%): Full capacity, but potentially over-parameterized\n","\n"," Learning Dynamics:\n","   - Sparse networks may learn more slowly but generalize differently\n","   - Dense networks learn faster but may overfit to training distribution\n","    \n","\n"," LATE STAGE FINDINGS (Normal vs ASD):\n"," ====================================\n","\n"," Overall Differences (Normal - ASD, averaged across all early densities):\n","   - Visual accuracy: -0.00% ± 0.02%\n","   - Stress tolerance: +9.49% ± 6.22%\n","   - Ambiguity tolerance: +0.60%\n","\n"," Statistical Interpretation:\n","   - Positive difference = Normal outperforms ASD\n","   - Negative difference = ASD outperforms Normal\n","\n"," Conclusion: ASD condition performs comparably or BETTER\n","   → Heavier late pruning (ASD) does NOT necessarily hurt performance\n","    \n","\n"," DENSITY-DEPENDENT EFFECTS:\n"," ------------------------------------------------------------\n","\n"," How does early density affect the Normal-ASD gap?\n","\n","   10% early density:\n","     → EQUAL by 0.0% (low starting density - already resource-constrained)\n","     → Final densities: Normal=8.0%, ASD=5.0%\n","   20% early density:\n","     → ASD BETTER by 0.0% (low starting density - already resource-constrained)\n","     → Final densities: Normal=16.0%, ASD=10.0%\n","   30% early density:\n","     → ASD BETTER by 0.0% (low starting density - already resource-constrained)\n","     → Final densities: Normal=24.0%, ASD=15.0%\n","   40% early density:\n","     → ASD BETTER by 0.0% (moderate starting density)\n","     → Final densities: Normal=32.0%, ASD=20.0%\n","   50% early density:\n","     → EQUAL by 0.0% (moderate starting density)\n","     → Final densities: Normal=40.0%, ASD=25.0%\n","   60% early density:\n","     → EQUAL by 0.0% (moderate starting density)\n","     → Final densities: Normal=48.0%, ASD=30.0%\n","   70% early density:\n","     → Normal BETTER by 0.0% (high starting density - ample resources)\n","     → Final densities: Normal=56.0%, ASD=35.0%\n","   80% early density:\n","     → Normal BETTER by 0.0% (high starting density - ample resources)\n","     → Final densities: Normal=64.0%, ASD=40.0%\n","   90% early density:\n","     → EQUAL by 0.0% (high starting density - ample resources)\n","     → Final densities: Normal=72.0%, ASD=45.0%\n","   100% early density:\n","     → ASD BETTER by 0.0% (high starting density - ample resources)\n","     → Final densities: Normal=80.0%, ASD=50.0%\n","\n","\n"," KEY INSIGHTS:\n"," =============\n","\n"," 1. Interaction Effect:\n","    The impact of late pruning depends critically on early density.\n","    - High early density provides \"buffer\" against late pruning damage\n","    - Low early density leaves network vulnerable to any further pruning\n","\n"," 2. Resilience Patterns:\n","    Networks with more initial connections can better absorb pruning\n","    without catastrophic performance loss.\n","\n"," 3. Implications for ASD Modeling:\n","    If ASD involves altered pruning dynamics, both timing AND magnitude matter:\n","    - Early hyper-connectivity + insufficient late pruning = one pattern\n","    - Normal early + excessive late pruning = different pattern (tested here)\n","\n"," 4. Stress and Ambiguity:\n","    These secondary metrics often show larger Normal-ASD gaps than basic accuracy,\n","    suggesting pruning affects robustness more than raw performance.\n","    \n","\n","================================================================================\n"," EXPERIMENT 1 COMPLETE\n","================================================================================\n","\n"," RESULTS STRUCTURE:\n"," ==================\n","\n"," sweep_results dictionary contains:\n","\n","   'baseline':\n","     Results for full density (100%) baseline network\n","\n","   'early_stage':\n","     Results for each density level (keys: 'early_10', 'early_20', ..., 'early_100')\n","     Each contains: visual_clear, voice_clear, stress metrics, ambiguity metrics, etc.\n","\n","   'late_stage_normal':\n","     Results after Normal pruning (20% removed) from each early state\n","     Keys: 'late_normal_10', 'late_normal_20', ..., 'late_normal_100'\n","\n","   'late_stage_asd':\n","     Results after ASD pruning (50% removed) from each early state\n","     Keys: 'late_asd_10', 'late_asd_20', ..., 'late_asd_100'\n","\n","   'comparisons':\n","     Direct Normal vs ASD comparisons at each early density\n","     Keys: 10, 20, 30, ..., 100 (integer density values)\n","     Each contains: visual_diff, stress_diff, ambig_diff, etc.\n","\n","   'learning_curves':\n","     Training history (loss, accuracy per epoch) for baseline and each early density\n","    \n","================================================================================\n"," END OF EXPERIMENT 1\n","================================================================================\n","\n"]}],"source":["\"\"\"\n","================================================================================\n","EXTENDED DEVELOPMENTAL PRUNING SIMULATION FOR AUTISM SPECTRUM DISORDER\n","================================================================================\n","\n","VERSION 9.2: DENSITY SWEEP WITH DIFFERENTIAL PRUNING\n","\n","EXPERIMENT 1: DENSITY SWEEP\n","---------------------------\n","EARLY STAGE:\n","  - Sweep densities from 10% to 100% (10% intervals)\n","  - Compare learning dynamics across density levels\n","  - This models different degrees of early developmental pruning\n","\n","LATE STAGE (for each early density):\n","  - Normal: 20% additional pruning from early state\n","  - ASD: 50% additional pruning from early state\n","  - Compare Normal vs ASD outcomes at each density level\n","\n","This design allows us to see:\n","1. How initial density affects learning and resilience\n","2. How the same starting point diverges with different late pruning\n","3. The interaction between early density and late pruning severity\n","\n","================================================================================\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, TensorDataset\n","from typing import Dict, Tuple, List\n","import warnings\n","\n","warnings.filterwarnings('ignore', category=UserWarning)\n","\n","\n","# ============================================================================\n","# SECTION 1: CONFIGURATION\n","# ============================================================================\n","\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","\n","DEVICE = torch.device('cpu')\n","\n","CONFIG = {\n","    # =======================================================================\n","    # DATA GENERATION PARAMETERS\n","    # =======================================================================\n","    'n_train': 12000,\n","    'n_test': 4000,\n","    'n_clean_test': 2000,\n","    'batch_size': 128,\n","\n","    # Visual task: Clear, well-separated clusters\n","    'visual_noise': 0.8,\n","    'visual_centers': [[-3, -3], [3, 3], [-3, 3], [3, -3]],\n","\n","    # Voice task: SAME centers as visual, PERMUTED labels (true conflict)\n","    'voice_noise': 0.8,\n","    'voice_label_permutation': [2, 3, 0, 1],\n","\n","    # =======================================================================\n","    # NETWORK ARCHITECTURE\n","    # =======================================================================\n","    'hidden_dims': [256, 256, 128],\n","    'input_dim': 2,\n","    'task_id_dim': 2,\n","    'output_dim': 4,\n","\n","    # =======================================================================\n","    # TRAINING HYPERPARAMETERS\n","    # =======================================================================\n","    'baseline_epochs': 30,\n","    'baseline_lr': 0.001,\n","    'finetune_lr': 0.0005,\n","    'multitask_epochs': 60,\n","\n","    # =======================================================================\n","    # VERSION 9.2: DENSITY SWEEP PARAMETERS\n","    # =======================================================================\n","    'early_density_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","    'early_training_epochs': 15,\n","\n","    # Late stage pruning (fraction to REMOVE from early state)\n","    'late_pruning_normal': 0.20,  # Remove 20% of remaining weights\n","    'late_pruning_asd': 0.50,     # Remove 50% of remaining weights\n","    'late_finetune_epochs': 10,\n","\n","    # =======================================================================\n","    # STRESS LEVELS\n","    # =======================================================================\n","    'stress_levels': {\n","        'none': 0.0,\n","        'mild': 0.5,\n","        'moderate': 1.0,\n","        'high': 2.0,\n","        'severe': 3.0\n","    },\n","\n","    # =======================================================================\n","    # TASK CONTEXT AMBIGUITY LEVELS\n","    # =======================================================================\n","    'ambiguity_levels': {\n","        'pure_visual': 1.0,\n","        'slight': 0.85,\n","        'moderate': 0.7,\n","        'high': 0.6,\n","        'severe': 0.55,\n","        'ambiguous': 0.5\n","    },\n","}\n","\n","\n","# ============================================================================\n","# SECTION 2: DATA GENERATION\n","# ============================================================================\n","\n","def generate_visual_blobs(\n","    n_samples: int = 10000,\n","    noise: float = None,\n","    seed: int = None\n",") -> Tuple[torch.Tensor, torch.Tensor]:\n","    if noise is None:\n","        noise = CONFIG['visual_noise']\n","\n","    rng = np.random.RandomState(seed) if seed else np.random.RandomState()\n","    centers = np.array(CONFIG['visual_centers'])\n","\n","    labels = rng.randint(0, 4, n_samples)\n","    data = centers[labels] + rng.randn(n_samples, 2) * noise\n","\n","    return (\n","        torch.tensor(data, dtype=torch.float32),\n","        torch.tensor(labels, dtype=torch.long)\n","    )\n","\n","\n","def generate_voice_blobs_conflicting(\n","    n_samples: int = 10000,\n","    noise: float = None,\n","    seed: int = None\n",") -> Tuple[torch.Tensor, torch.Tensor]:\n","    if noise is None:\n","        noise = CONFIG['voice_noise']\n","\n","    rng = np.random.RandomState(seed) if seed else np.random.RandomState()\n","    centers = np.array(CONFIG['visual_centers'])\n","\n","    original_labels = rng.randint(0, 4, n_samples)\n","    data = centers[original_labels] + rng.randn(n_samples, 2) * noise\n","\n","    permutation = CONFIG['voice_label_permutation']\n","    conflicting_labels = np.array([permutation[l] for l in original_labels])\n","\n","    return (\n","        torch.tensor(data, dtype=torch.float32),\n","        torch.tensor(conflicting_labels, dtype=torch.long)\n","    )\n","\n","\n","def create_multitask_data_loaders() -> Dict[str, DataLoader]:\n","    print(\"\\n\" + \"=\"*70)\n","    print(\" CREATING TASK-GATED MULTI-TASK DATA LOADERS\")\n","    print(\"=\"*70)\n","\n","    print(\"\\n Generating Visual Task Data...\")\n","    print(f\"   - Training samples: {CONFIG['n_train']:,}\")\n","    print(f\"   - Test samples: {CONFIG['n_test']:,}\")\n","    print(f\"   - Clean test samples: {CONFIG['n_clean_test']:,}\")\n","    print(f\"   - Noise level: {CONFIG['visual_noise']}\")\n","    print(f\"   - Cluster centers: {CONFIG['visual_centers']}\")\n","\n","    visual_train_data, visual_train_labels = generate_visual_blobs(CONFIG['n_train'], seed=100)\n","    visual_test_data, visual_test_labels = generate_visual_blobs(CONFIG['n_test'], seed=200)\n","    visual_clean_data, visual_clean_labels = generate_visual_blobs(CONFIG['n_clean_test'], noise=0.0, seed=300)\n","\n","    print(\"\\n Generating Voice Task Data (CONFLICTING labels)...\")\n","    print(f\"   - Training samples: {CONFIG['n_train']:,}\")\n","    print(f\"   - Test samples: {CONFIG['n_test']:,}\")\n","    print(f\"   - Noise level: {CONFIG['voice_noise']}\")\n","    print(f\"   - Label permutation: {CONFIG['voice_label_permutation']}\")\n","    print(\"   - NOTE: Same spatial distribution as visual, but labels are permuted\")\n","\n","    voice_train_data, voice_train_labels = generate_voice_blobs_conflicting(CONFIG['n_train'], seed=400)\n","    voice_test_data, voice_test_labels = generate_voice_blobs_conflicting(CONFIG['n_test'], seed=500)\n","\n","    loaders = {\n","        'visual_train': DataLoader(TensorDataset(visual_train_data, visual_train_labels),\n","                                   batch_size=CONFIG['batch_size'], shuffle=True),\n","        'visual_test': DataLoader(TensorDataset(visual_test_data, visual_test_labels),\n","                                  batch_size=1000, shuffle=False),\n","        'visual_clean': DataLoader(TensorDataset(visual_clean_data, visual_clean_labels),\n","                                   batch_size=1000, shuffle=False),\n","        'voice_train': DataLoader(TensorDataset(voice_train_data, voice_train_labels),\n","                                  batch_size=CONFIG['batch_size'], shuffle=True),\n","        'voice_test': DataLoader(TensorDataset(voice_test_data, voice_test_labels),\n","                                 batch_size=1000, shuffle=False),\n","        'visual_test_data': visual_test_data,\n","        'visual_test_labels': visual_test_labels,\n","        'voice_test_data': voice_test_data,\n","        'voice_test_labels': voice_test_labels\n","    }\n","\n","    print(\"\\n Data Loaders Created Successfully:\")\n","    print(f\"   - Visual train loader: {len(loaders['visual_train'])} batches\")\n","    print(f\"   - Visual test loader: {len(loaders['visual_test'])} batches\")\n","    print(f\"   - Voice train loader: {len(loaders['voice_train'])} batches\")\n","    print(f\"   - Voice test loader: {len(loaders['voice_test'])} batches\")\n","    print(f\"   - Batch size: {CONFIG['batch_size']}\")\n","\n","    return loaders\n","\n","\n","# ============================================================================\n","# SECTION 3: NETWORK\n","# ============================================================================\n","\n","class TaskGatedNetwork(nn.Module):\n","    def __init__(self, hidden_dims: List[int] = None):\n","        super().__init__()\n","\n","        if hidden_dims is None:\n","            hidden_dims = CONFIG['hidden_dims']\n","\n","        input_dim = CONFIG['input_dim'] + CONFIG['task_id_dim']\n","\n","        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n","        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n","        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n","        self.head = nn.Linear(hidden_dims[2], CONFIG['output_dim'])\n","\n","        self.relu = nn.ReLU()\n","        self.stress_level = 0.0\n","\n","        self.weight_layers = ['fc1', 'fc2', 'fc3', 'head']\n","        self.backbone_layers = ['fc1', 'fc2', 'fc3']\n","\n","    def set_stress(self, level: float):\n","        self.stress_level = level\n","\n","    def forward(self, x: torch.Tensor, task_id: torch.Tensor) -> torch.Tensor:\n","        combined = torch.cat([x, task_id], dim=1)\n","\n","        h = self.fc1(combined)\n","        h = self.relu(h)\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","\n","        h = self.fc2(h)\n","        h = self.relu(h)\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","\n","        h = self.fc3(h)\n","        h = self.relu(h)\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","\n","        return self.head(h)\n","\n","    def count_parameters(self) -> Tuple[int, int]:\n","        total = sum(p.numel() for p in self.parameters())\n","        nonzero = sum((p != 0).sum().item() for p in self.parameters())\n","        return total, nonzero\n","\n","    def print_architecture(self):\n","        print(\"\\n\" + \"-\"*50)\n","        print(\" NETWORK ARCHITECTURE\")\n","        print(\"-\"*50)\n","        print(f\"   Input dimension: {CONFIG['input_dim']} + {CONFIG['task_id_dim']} (task ID) = {CONFIG['input_dim'] + CONFIG['task_id_dim']}\")\n","        print(f\"   Hidden layers: {CONFIG['hidden_dims']}\")\n","        print(f\"   Output dimension: {CONFIG['output_dim']}\")\n","        print(\"\\n   Layer Details:\")\n","        for name, param in self.named_parameters():\n","            print(f\"     {name}: {list(param.shape)}\")\n","        total, nonzero = self.count_parameters()\n","        print(f\"\\n   Total parameters: {total:,}\")\n","        print(f\"   Non-zero parameters: {nonzero:,}\")\n","        print(\"-\"*50)\n","\n","\n","# ============================================================================\n","# SECTION 4: PRUNING MANAGER\n","# ============================================================================\n","\n","class TaskGatedPruningManager:\n","    def __init__(self, model: TaskGatedNetwork, prune_head: bool = True):\n","        self.model = model\n","        self.prune_head = prune_head\n","        self.masks = {}\n","        self.history = []\n","        self.gradient_buffer = {}\n","\n","        for name, param in model.named_parameters():\n","            if 'weight' in name and param.dim() >= 2:\n","                layer_name = name.replace('.weight', '')\n","                if prune_head or layer_name in model.backbone_layers:\n","                    self.masks[name] = torch.ones_like(param, dtype=torch.float32)\n","                    self.gradient_buffer[name] = torch.zeros_like(param)\n","\n","    def prune_by_magnitude(self, sparsity: float, per_layer: bool = True) -> Dict[str, Dict]:\n","        stats = {}\n","\n","        if per_layer:\n","            for name, param in self.model.named_parameters():\n","                if name in self.masks:\n","                    weights = param.data.abs()\n","                    threshold = torch.quantile(weights.flatten(), sparsity)\n","                    self.masks[name] = (weights >= threshold).float()\n","                    param.data *= self.masks[name]\n","\n","                    kept = self.masks[name].sum().item()\n","                    total = self.masks[name].numel()\n","                    stats[name] = {'kept': int(kept), 'total': total, 'actual_sparsity': 1 - kept/total}\n","        else:\n","            all_weights = torch.cat([\n","                self.model.get_parameter(name).data.abs().flatten()\n","                for name in self.masks\n","            ])\n","            threshold = torch.quantile(all_weights, sparsity)\n","\n","            for name, param in self.model.named_parameters():\n","                if name in self.masks:\n","                    self.masks[name] = (param.data.abs() >= threshold).float()\n","                    param.data *= self.masks[name]\n","\n","                    kept = self.masks[name].sum().item()\n","                    total = self.masks[name].numel()\n","                    stats[name] = {'kept': int(kept), 'total': total, 'actual_sparsity': 1 - kept/total}\n","\n","        self.history.append(('prune', sparsity, stats))\n","        return stats\n","\n","    def prune_to_density(self, target_density: float, per_layer: bool = True) -> Dict[str, Dict]:\n","        target_sparsity = 1.0 - target_density\n","        return self.prune_by_magnitude(target_sparsity, per_layer)\n","\n","    def prune_fraction_of_remaining(self, fraction_to_remove: float, per_layer: bool = True) -> Dict[str, Dict]:\n","        \"\"\"Remove a fraction of currently active weights.\"\"\"\n","        stats = {}\n","\n","        for name, param in self.model.named_parameters():\n","            if name not in self.masks:\n","                continue\n","\n","            mask = self.masks[name]\n","            active_positions = (mask == 1)\n","            active_weights = param.data.abs() * active_positions.float()\n","\n","            num_active = active_positions.sum().item()\n","            if num_active == 0:\n","                stats[name] = {'removed': 0, 'remaining': 0, 'fraction': 0}\n","                continue\n","\n","            num_to_remove = int(fraction_to_remove * num_active)\n","            if num_to_remove == 0:\n","                stats[name] = {'removed': 0, 'remaining': int(num_active), 'fraction': 0}\n","                continue\n","\n","            # Get threshold for bottom fraction_to_remove of active weights\n","            active_values = param.data.abs()[active_positions]\n","            threshold = torch.quantile(active_values, fraction_to_remove)\n","\n","            # Create new mask: keep weights above threshold AND currently active\n","            new_mask = ((param.data.abs() >= threshold) & active_positions).float()\n","\n","            self.masks[name] = new_mask\n","            param.data *= new_mask\n","\n","            new_active = new_mask.sum().item()\n","            stats[name] = {\n","                'removed': int(num_active - new_active),\n","                'remaining': int(new_active),\n","                'fraction': (num_active - new_active) / num_active if num_active > 0 else 0\n","            }\n","\n","        self.history.append(('prune_fraction', fraction_to_remove, stats))\n","        return stats\n","\n","    def apply_masks(self):\n","        with torch.no_grad():\n","            for name, param in self.model.named_parameters():\n","                if name in self.masks:\n","                    param.data *= self.masks[name]\n","\n","    def get_sparsity(self) -> float:\n","        total_params = sum(m.numel() for m in self.masks.values())\n","        zero_params = sum((m == 0).sum().item() for m in self.masks.values())\n","        return zero_params / total_params if total_params > 0 else 0.0\n","\n","    def get_density(self) -> float:\n","        return 1.0 - self.get_sparsity()\n","\n","    def print_mask_stats(self, label: str = \"\"):\n","        print(f\"\\n   Mask Statistics {label}:\")\n","        total_params = 0\n","        total_active = 0\n","        for name, mask in self.masks.items():\n","            active = mask.sum().item()\n","            total = mask.numel()\n","            total_params += total\n","            total_active += active\n","            print(f\"     {name}: {int(active):,}/{total:,} active ({100*active/total:.1f}%)\")\n","        print(f\"     TOTAL: {int(total_active):,}/{total_params:,} active ({100*total_active/total_params:.1f}%)\")\n","\n","\n","# ============================================================================\n","# SECTION 5: TRAINING\n","# ============================================================================\n","\n","def train_taskgated_with_curves(\n","    model: TaskGatedNetwork,\n","    loaders: Dict[str, DataLoader],\n","    epochs: int = None,\n","    lr: float = None,\n","    pruning_manager: TaskGatedPruningManager = None,\n","    verbose: bool = True,\n","    track_test_accuracy: bool = True\n",") -> Dict[str, List[float]]:\n","\n","    if epochs is None:\n","        epochs = CONFIG['multitask_epochs']\n","    if lr is None:\n","        lr = CONFIG['baseline_lr']\n","\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    history = {\n","        'visual_loss': [], 'voice_loss': [], 'combined_loss': [],\n","        'visual_acc': [], 'voice_acc': []\n","    }\n","\n","    visual_task_id = torch.tensor([[1.0, 0.0]]).to(DEVICE)\n","    voice_task_id = torch.tensor([[0.0, 1.0]]).to(DEVICE)\n","\n","    model.set_stress(0.0)\n","\n","    if verbose:\n","        print(f\"\\n   Training Configuration:\")\n","        print(f\"     - Epochs: {epochs}\")\n","        print(f\"     - Learning rate: {lr}\")\n","        print(f\"     - Optimizer: Adam\")\n","        print(f\"     - Loss function: CrossEntropyLoss\")\n","        if pruning_manager:\n","            print(f\"     - Pruning manager: Active (density={pruning_manager.get_density()*100:.1f}%)\")\n","        print()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        visual_loss = 0.0\n","        voice_loss = 0.0\n","        visual_batches = 0\n","        voice_batches = 0\n","\n","        visual_iter = iter(loaders['visual_train'])\n","        voice_iter = iter(loaders['voice_train'])\n","\n","        done = False\n","        batch_idx = 0\n","\n","        while not done:\n","            try:\n","                x_v, y_v = next(visual_iter)\n","                x_v, y_v = x_v.to(DEVICE), y_v.to(DEVICE)\n","                batch_size = x_v.size(0)\n","                task_id = visual_task_id.repeat(batch_size, 1)\n","\n","                optimizer.zero_grad()\n","                output = model(x_v, task_id)\n","                loss = loss_fn(output, y_v)\n","                loss.backward()\n","                optimizer.step()\n","\n","                if pruning_manager:\n","                    pruning_manager.apply_masks()\n","\n","                visual_loss += loss.item()\n","                visual_batches += 1\n","            except StopIteration:\n","                visual_iter = iter(loaders['visual_train'])\n","\n","            try:\n","                x_a, y_a = next(voice_iter)\n","                x_a, y_a = x_a.to(DEVICE), y_a.to(DEVICE)\n","                batch_size = x_a.size(0)\n","                task_id = voice_task_id.repeat(batch_size, 1)\n","\n","                optimizer.zero_grad()\n","                output = model(x_a, task_id)\n","                loss = loss_fn(output, y_a)\n","                loss.backward()\n","                optimizer.step()\n","\n","                if pruning_manager:\n","                    pruning_manager.apply_masks()\n","\n","                voice_loss += loss.item()\n","                voice_batches += 1\n","            except StopIteration:\n","                voice_iter = iter(loaders['voice_train'])\n","\n","            batch_idx += 1\n","            if batch_idx >= len(loaders['visual_train']):\n","                done = True\n","\n","        avg_visual_loss = visual_loss / max(visual_batches, 1)\n","        avg_voice_loss = voice_loss / max(voice_batches, 1)\n","        avg_combined_loss = (avg_visual_loss + avg_voice_loss) / 2\n","\n","        history['visual_loss'].append(avg_visual_loss)\n","        history['voice_loss'].append(avg_voice_loss)\n","        history['combined_loss'].append(avg_combined_loss)\n","\n","        if track_test_accuracy:\n","            visual_acc = evaluate_task_quick(model, loaders, 'visual')\n","            voice_acc = evaluate_task_quick(model, loaders, 'voice')\n","            history['visual_acc'].append(visual_acc)\n","            history['voice_acc'].append(voice_acc)\n","\n","        if verbose and (epoch + 1) % 5 == 0:\n","            if track_test_accuracy:\n","                print(f\"    Epoch {epoch+1:>3}/{epochs}: Loss V={avg_visual_loss:.4f} A={avg_voice_loss:.4f} \"\n","                      f\"Combined={avg_combined_loss:.4f} | Acc V={history['visual_acc'][-1]:.1f}% A={history['voice_acc'][-1]:.1f}%\")\n","            else:\n","                print(f\"    Epoch {epoch+1:>3}/{epochs}: Loss V={avg_visual_loss:.4f} A={avg_voice_loss:.4f} \"\n","                      f\"Combined={avg_combined_loss:.4f}\")\n","\n","    if verbose:\n","        print(f\"\\n   Training Complete:\")\n","        print(f\"     - Final combined loss: {history['combined_loss'][-1]:.4f}\")\n","        if track_test_accuracy:\n","            print(f\"     - Final visual accuracy: {history['visual_acc'][-1]:.1f}%\")\n","            print(f\"     - Final voice accuracy: {history['voice_acc'][-1]:.1f}%\")\n","\n","    return history\n","\n","\n","def evaluate_task_quick(model: TaskGatedNetwork, loaders: Dict[str, DataLoader], task: str = 'visual') -> float:\n","    model.eval()\n","    model.set_stress(0.0)\n","\n","    if task == 'visual':\n","        loader = loaders['visual_test']\n","        task_id_base = torch.tensor([[1.0, 0.0]]).to(DEVICE)\n","    else:\n","        loader = loaders['voice_test']\n","        task_id_base = torch.tensor([[0.0, 1.0]]).to(DEVICE)\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            batch_size = x.size(0)\n","            task_id = task_id_base.repeat(batch_size, 1)\n","            predictions = model(x, task_id).argmax(dim=1)\n","            correct += (predictions == y).sum().item()\n","            total += y.size(0)\n","\n","    model.train()\n","    return 100.0 * correct / total\n","\n","\n","# ============================================================================\n","# SECTION 6: EVALUATION\n","# ============================================================================\n","\n","def evaluate_task(model: TaskGatedNetwork, loaders: Dict[str, DataLoader],\n","                  task: str = 'visual', internal_stress: float = 0.0) -> float:\n","    model.eval()\n","    model.set_stress(internal_stress)\n","\n","    if task == 'visual':\n","        loader = loaders['visual_test']\n","        task_id_base = torch.tensor([[1.0, 0.0]]).to(DEVICE)\n","    else:\n","        loader = loaders['voice_test']\n","        task_id_base = torch.tensor([[0.0, 1.0]]).to(DEVICE)\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            batch_size = x.size(0)\n","            task_id = task_id_base.repeat(batch_size, 1)\n","            predictions = model(x, task_id).argmax(dim=1)\n","            correct += (predictions == y).sum().item()\n","            total += y.size(0)\n","\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","def evaluate_with_ambiguous_context(model: TaskGatedNetwork, loaders: Dict[str, DataLoader],\n","                                    visual_weight: float = 0.5, internal_stress: float = 0.0) -> float:\n","    model.eval()\n","    model.set_stress(internal_stress)\n","\n","    visual_data = loaders['visual_test_data']\n","    visual_labels = loaders['visual_test_labels']\n","    task_id_base = torch.tensor([[visual_weight, 1 - visual_weight]]).to(DEVICE)\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        batch_size = 1000\n","        n_samples = len(visual_data)\n","\n","        for start in range(0, n_samples, batch_size):\n","            end = min(start + batch_size, n_samples)\n","            x = visual_data[start:end].to(DEVICE)\n","            y = visual_labels[start:end].to(DEVICE)\n","            task_id = task_id_base.repeat(x.size(0), 1)\n","            predictions = model(x, task_id).argmax(dim=1)\n","            correct += (predictions == y).sum().item()\n","            total += y.size(0)\n","\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","def evaluate_with_blended_input_and_ambiguous_context(\n","    model: TaskGatedNetwork, loaders: Dict[str, DataLoader],\n","    input_blend: float = 0.5, visual_weight: float = 0.5, internal_stress: float = 0.0) -> float:\n","\n","    model.eval()\n","    model.set_stress(internal_stress)\n","\n","    visual_data = loaders['visual_test_data']\n","    visual_labels = loaders['visual_test_labels']\n","    voice_data = loaders['voice_test_data']\n","    task_id_base = torch.tensor([[visual_weight, 1 - visual_weight]]).to(DEVICE)\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        batch_size = 1000\n","        n_samples = len(visual_data)\n","\n","        for start in range(0, n_samples, batch_size):\n","            end = min(start + batch_size, n_samples)\n","            x_visual = visual_data[start:end].to(DEVICE)\n","            y_visual = visual_labels[start:end].to(DEVICE)\n","            indices = torch.randint(0, len(voice_data), (end - start,))\n","            x_voice = voice_data[indices].to(DEVICE)\n","            x_blended = (1 - input_blend) * x_visual + input_blend * x_voice\n","            task_id = task_id_base.repeat(x_blended.size(0), 1)\n","            predictions = model(x_blended, task_id).argmax(dim=1)\n","            correct += (predictions == y_visual).sum().item()\n","            total += y_visual.size(0)\n","\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","def comprehensive_evaluation(model: TaskGatedNetwork, loaders: Dict[str, DataLoader],\n","                             label: str, print_results: bool = True) -> Dict[str, float]:\n","    results = {}\n","    model.set_stress(0.0)\n","\n","    results['visual_clear'] = evaluate_task(model, loaders, 'visual')\n","    results['voice_clear'] = evaluate_task(model, loaders, 'voice')\n","\n","    for stress_name, stress_level in CONFIG['stress_levels'].items():\n","        if stress_level > 0:\n","            results[f'visual_stress_{stress_name}'] = evaluate_task(\n","                model, loaders, 'visual', internal_stress=stress_level)\n","\n","    for amb_name, visual_weight in CONFIG['ambiguity_levels'].items():\n","        results[f'visual_ambig_{amb_name}'] = evaluate_with_ambiguous_context(\n","            model, loaders, visual_weight=visual_weight)\n","\n","    baseline = results['visual_clear']\n","    for amb_name, visual_weight in CONFIG['ambiguity_levels'].items():\n","        if visual_weight < 1.0:\n","            ambig_acc = results[f'visual_ambig_{amb_name}']\n","            drop = baseline - ambig_acc\n","            relative_drop = (drop / baseline * 100) if baseline > 0 else 0\n","            results[f'ambig_drop_{amb_name}'] = drop\n","            results[f'ambig_drop_pct_{amb_name}'] = relative_drop\n","\n","    results['visual_blend50_ambig'] = evaluate_with_blended_input_and_ambiguous_context(\n","        model, loaders, input_blend=0.5, visual_weight=0.5)\n","    results['visual_blend30_clear'] = evaluate_with_blended_input_and_ambiguous_context(\n","        model, loaders, input_blend=0.3, visual_weight=1.0)\n","    results['visual_blend50_clear'] = evaluate_with_blended_input_and_ambiguous_context(\n","        model, loaders, input_blend=0.5, visual_weight=1.0)\n","\n","    total, nonzero = model.count_parameters()\n","    results['sparsity'] = 100 * (1 - nonzero / total)\n","    results['density'] = 100 * (nonzero / total)\n","    results['total_params'] = total\n","    results['nonzero_params'] = nonzero\n","\n","    if print_results:\n","        print(f\"\\n{'='*70}\")\n","        print(f\" EVALUATION: {label}\")\n","        print(f\"{'='*70}\")\n","        print(f\"\\n Network Statistics:\")\n","        print(f\"   Total parameters: {total:,}\")\n","        print(f\"   Non-zero parameters: {nonzero:,}\")\n","        print(f\"   Density: {results['density']:.1f}%\")\n","        print(f\"   Sparsity: {results['sparsity']:.1f}%\")\n","\n","        print(f\"\\n Basic Task Performance:\")\n","        print(f\"   Visual task accuracy: {results['visual_clear']:.1f}%\")\n","        print(f\"   Voice task accuracy: {results['voice_clear']:.1f}%\")\n","\n","        print(f\"\\n Stress Tolerance (Visual Task):\")\n","        for stress_name, stress_level in CONFIG['stress_levels'].items():\n","            if stress_level > 0:\n","                acc = results[f'visual_stress_{stress_name}']\n","                drop = results['visual_clear'] - acc\n","                print(f\"   {stress_name.capitalize():>10} (σ={stress_level:.1f}): {acc:.1f}% (drop: {drop:+.1f}%)\")\n","\n","        print(f\"\\n Ambiguity Tolerance (Visual Task):\")\n","        for amb_name, visual_weight in CONFIG['ambiguity_levels'].items():\n","            acc = results[f'visual_ambig_{amb_name}']\n","            if visual_weight < 1.0:\n","                drop = results[f'ambig_drop_{amb_name}']\n","                print(f\"   {amb_name.capitalize():>12} (w={visual_weight:.2f}): {acc:.1f}% (drop: {drop:+.1f}%)\")\n","            else:\n","                print(f\"   {amb_name.capitalize():>12} (w={visual_weight:.2f}): {acc:.1f}%\")\n","\n","        print(f\"\\n Blended Input Tests:\")\n","        print(f\"   50% blend + ambiguous context: {results['visual_blend50_ambig']:.1f}%\")\n","        print(f\"   30% blend + clear context: {results['visual_blend30_clear']:.1f}%\")\n","        print(f\"   50% blend + clear context: {results['visual_blend50_clear']:.1f}%\")\n","\n","    return results\n","\n","\n","# ============================================================================\n","# SECTION 7: DENSITY SWEEP EXPERIMENT (EXPERIMENT 1)\n","# ============================================================================\n","\n","def run_density_sweep_experiment() -> Dict[str, Dict]:\n","    \"\"\"\n","    EXPERIMENT 1: Density sweep with differential late pruning\n","\n","    EARLY STAGE: For each density level (10% to 100%):\n","      - Prune to target density\n","      - Train for fixed epochs\n","      - Evaluate and compare across densities\n","\n","    LATE STAGE: For each early density:\n","      - Normal arm: Remove 20% of remaining weights\n","      - ASD arm: Remove 50% of remaining weights\n","      - Compare Normal vs ASD at each density\n","    \"\"\"\n","    print(\"\\n\" + \"#\"*80)\n","    print(\"#\" + \" EXPERIMENT 1: DENSITY SWEEP WITH DIFFERENTIAL LATE PRUNING \".center(78) + \"#\")\n","    print(\"#\" + \" Version 9.2: Comprehensive Early/Late Stage Comparison \".center(78) + \"#\")\n","    print(\"#\"*80)\n","\n","    print(f\"\"\"\n"," EXPERIMENTAL DESIGN:\n"," ====================\n","\n"," EARLY STAGE (density sweep):\n","   Densities tested: {[f'{d*100:.0f}%' for d in CONFIG['early_density_levels']]}\n","   Training epochs per density: {CONFIG['early_training_epochs']}\n","   Learning rate: {CONFIG['finetune_lr']}\n","\n"," LATE STAGE (differential pruning from each early state):\n","   Normal condition: Remove {CONFIG['late_pruning_normal']*100:.0f}% of remaining weights\n","   ASD condition: Remove {CONFIG['late_pruning_asd']*100:.0f}% of remaining weights\n","   Fine-tuning epochs: {CONFIG['late_finetune_epochs']}\n","\n"," RATIONALE:\n","   This design tests how initial network density (early pruning) affects:\n","   1. Baseline learning capacity\n","   2. Resilience to further pruning (late stage)\n","   3. The differential impact of normal vs. excessive late pruning\n","    \"\"\")\n","\n","    loaders = create_multitask_data_loaders()\n","\n","    all_results = {\n","        'early_stage': {},\n","        'late_stage_normal': {},\n","        'late_stage_asd': {},\n","        'learning_curves': {},\n","        'comparisons': {}\n","    }\n","\n","    # ========================================================================\n","    # STAGE 0: Train full density baseline\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" STAGE 0: TRAINING FULL DENSITY BASELINE\")\n","    print(\"=\"*80)\n","\n","    print(\"\\n Creating full density network...\")\n","    full_model = TaskGatedNetwork().to(DEVICE)\n","    full_model.print_architecture()\n","\n","    print(f\"\\n Training baseline model for {CONFIG['baseline_epochs']} epochs...\")\n","    full_history = train_taskgated_with_curves(\n","        full_model, loaders,\n","        epochs=CONFIG['baseline_epochs'],\n","        verbose=True,\n","        track_test_accuracy=True\n","    )\n","\n","    all_results['baseline'] = comprehensive_evaluation(\n","        full_model, loaders, \"FULL DENSITY BASELINE (100%)\", print_results=True\n","    )\n","    all_results['learning_curves']['baseline'] = full_history\n","\n","    full_state = {k: v.clone() for k, v in full_model.state_dict().items()}\n","    print(\"\\n Baseline state saved for density sweep experiments.\")\n","\n","    # ========================================================================\n","    # EARLY STAGE: Density Sweep\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" EARLY STAGE: DENSITY SWEEP (10% to 100%)\")\n","    print(\" Comparing learning dynamics across density levels\")\n","    print(\"=\"*80)\n","\n","    early_states = {}  # Store states for late stage\n","    early_masks = {}   # Store masks for late stage\n","\n","    print(f\"\\n Testing {len(CONFIG['early_density_levels'])} density levels...\")\n","    print(f\" Each model starts from baseline, is pruned to target density, then trained for {CONFIG['early_training_epochs']} epochs.\\n\")\n","\n","    for i, target_density in enumerate(CONFIG['early_density_levels']):\n","        density_pct = int(target_density * 100)\n","\n","        print(\"\\n\" + \"-\"*70)\n","        print(f\" EARLY STAGE - Density Level {i+1}/{len(CONFIG['early_density_levels'])}: {density_pct}%\")\n","        print(\"-\"*70)\n","\n","        # Skip very low density (essentially no parameters)\n","        if target_density < 0.05:\n","            print(f\"   SKIPPED: Density {density_pct}% is too sparse for meaningful learning.\")\n","            continue\n","\n","        # Create model from full state\n","        print(f\"\\n   Loading baseline state...\")\n","        model = TaskGatedNetwork().to(DEVICE)\n","        model.load_state_dict(full_state)\n","        mgr = TaskGatedPruningManager(model)\n","\n","        # Prune to target density\n","        print(f\"   Pruning to {density_pct}% density...\")\n","        prune_stats = mgr.prune_to_density(target_density)\n","        actual_density = mgr.get_density() * 100\n","\n","        print(f\"   Pruning complete:\")\n","        for layer_name, stats in prune_stats.items():\n","            print(f\"     {layer_name}: kept {stats['kept']:,}/{stats['total']:,} weights ({(1-stats['actual_sparsity'])*100:.1f}% density)\")\n","\n","        mgr.print_mask_stats(f\"(Target: {density_pct}%)\")\n","\n","        # Train at this density\n","        print(f\"\\n   Training for {CONFIG['early_training_epochs']} epochs at {actual_density:.1f}% density...\")\n","        history = train_taskgated_with_curves(\n","            model, loaders,\n","            epochs=CONFIG['early_training_epochs'],\n","            lr=CONFIG['finetune_lr'],\n","            pruning_manager=mgr,\n","            verbose=True,\n","            track_test_accuracy=True\n","        )\n","\n","        # Evaluate\n","        key = f\"early_{density_pct}\"\n","        results = comprehensive_evaluation(\n","            model, loaders,\n","            f\"EARLY STAGE - {density_pct}% Density\",\n","            print_results=True\n","        )\n","        results['target_density'] = target_density * 100\n","        results['actual_density'] = actual_density\n","\n","        all_results['early_stage'][key] = results\n","        all_results['learning_curves'][key] = history\n","\n","        # Save state for late stage\n","        early_states[density_pct] = {k: v.clone() for k, v in model.state_dict().items()}\n","        early_masks[density_pct] = {k: v.clone() for k, v in mgr.masks.items()}\n","\n","        print(f\"\\n   State saved for late stage experiments.\")\n","\n","    # Early Stage Summary Table\n","    print(\"\\n\" + \"=\"*70)\n","    print(\" EARLY STAGE SUMMARY TABLE\")\n","    print(\"=\"*70)\n","    print(f\"\\n {'Density':>10} {'Visual':>10} {'Voice':>10} {'Stress Hi':>12} {'Ambiguous':>12} {'Blend+Ambig':>12}\")\n","    print(\" \" + \"-\"*75)\n","\n","    for density_pct in sorted([int(d*100) for d in CONFIG['early_density_levels'] if d >= 0.1]):\n","        key = f\"early_{density_pct}\"\n","        if key in all_results['early_stage']:\n","            r = all_results['early_stage'][key]\n","            print(f\" {r['actual_density']:>9.1f}% {r['visual_clear']:>9.1f}% {r['voice_clear']:>9.1f}% \"\n","                  f\"{r.get('visual_stress_high', 0):>11.1f}% {r.get('visual_ambig_ambiguous', 0):>11.1f}% \"\n","                  f\"{r.get('visual_blend50_ambig', 0):>11.1f}%\")\n","\n","    # ========================================================================\n","    # LATE STAGE: Differential Pruning\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" LATE STAGE: DIFFERENTIAL PRUNING (Normal vs ASD)\")\n","    print(\"=\"*80)\n","    print(f\"\"\"\n"," For each early density state, we now apply additional late-stage pruning:\n","   - Normal condition: Remove {CONFIG['late_pruning_normal']*100:.0f}% of remaining weights\n","   - ASD condition: Remove {CONFIG['late_pruning_asd']*100:.0f}% of remaining weights\n","\n"," This models developmental scenarios where:\n","   - Normal development has moderate synaptic pruning during adolescence\n","   - ASD may have insufficient pruning (this experiment tests EXCESSIVE pruning as comparison)\n","    \"\"\")\n","\n","    for density_pct in sorted(early_states.keys()):\n","        print(\"\\n\" + \"=\"*70)\n","        print(f\" LATE STAGE: Starting from EARLY {density_pct}% Density\")\n","        print(\"=\"*70)\n","\n","        early_density = density_pct\n","        early_results = all_results['early_stage'][f'early_{density_pct}']\n","\n","        print(f\"\\n   Early stage baseline performance:\")\n","        print(f\"     Visual accuracy: {early_results['visual_clear']:.1f}%\")\n","        print(f\"     Voice accuracy: {early_results['voice_clear']:.1f}%\")\n","        print(f\"     Stress tolerance (high): {early_results.get('visual_stress_high', 0):.1f}%\")\n","        print(f\"     Ambiguity tolerance: {early_results.get('visual_ambig_ambiguous', 0):.1f}%\")\n","\n","        # ----------------------------------------------------------------\n","        # NORMAL ARM: 20% additional pruning\n","        # ----------------------------------------------------------------\n","        print(\"\\n\" + \"-\"*60)\n","        print(f\"   NORMAL CONDITION: Remove {CONFIG['late_pruning_normal']*100:.0f}% of remaining weights\")\n","        print(\"-\"*60)\n","\n","        print(f\"\\n   Loading early state ({density_pct}% density)...\")\n","        normal_model = TaskGatedNetwork().to(DEVICE)\n","        normal_model.load_state_dict(early_states[density_pct])\n","        normal_mgr = TaskGatedPruningManager(normal_model)\n","        normal_mgr.masks = {k: v.clone() for k, v in early_masks[density_pct].items()}\n","\n","        pre_prune_density = normal_mgr.get_density() * 100\n","        print(f\"   Pre-pruning density: {pre_prune_density:.1f}%\")\n","\n","        # Apply additional pruning\n","        print(f\"   Applying {CONFIG['late_pruning_normal']*100:.0f}% additional pruning...\")\n","        prune_stats = normal_mgr.prune_fraction_of_remaining(CONFIG['late_pruning_normal'])\n","        normal_density = normal_mgr.get_density() * 100\n","\n","        print(f\"   Pruning details:\")\n","        for layer_name, stats in prune_stats.items():\n","            print(f\"     {layer_name}: removed {stats['removed']:,} weights, {stats['remaining']:,} remaining ({stats['fraction']*100:.1f}% removed)\")\n","\n","        print(f\"   Post-pruning density: {normal_density:.1f}%\")\n","\n","        # Fine-tune\n","        print(f\"\\n   Fine-tuning for {CONFIG['late_finetune_epochs']} epochs...\")\n","        train_taskgated_with_curves(\n","            normal_model, loaders,\n","            epochs=CONFIG['late_finetune_epochs'],\n","            lr=CONFIG['finetune_lr'],\n","            pruning_manager=normal_mgr,\n","            verbose=True,\n","            track_test_accuracy=True\n","        )\n","\n","        key_normal = f\"late_normal_{density_pct}\"\n","        results_normal = comprehensive_evaluation(\n","            normal_model, loaders,\n","            f\"LATE NORMAL (from {density_pct}% → {normal_density:.1f}%)\",\n","            print_results=True\n","        )\n","        results_normal['early_density'] = early_density\n","        results_normal['final_density'] = normal_density\n","        results_normal['pruning_fraction'] = CONFIG['late_pruning_normal']\n","        all_results['late_stage_normal'][key_normal] = results_normal\n","\n","        # ----------------------------------------------------------------\n","        # ASD ARM: 50% additional pruning\n","        # ----------------------------------------------------------------\n","        print(\"\\n\" + \"-\"*60)\n","        print(f\"   ASD CONDITION: Remove {CONFIG['late_pruning_asd']*100:.0f}% of remaining weights\")\n","        print(\"-\"*60)\n","\n","        print(f\"\\n   Loading early state ({density_pct}% density)...\")\n","        asd_model = TaskGatedNetwork().to(DEVICE)\n","        asd_model.load_state_dict(early_states[density_pct])\n","        asd_mgr = TaskGatedPruningManager(asd_model)\n","        asd_mgr.masks = {k: v.clone() for k, v in early_masks[density_pct].items()}\n","\n","        pre_prune_density = asd_mgr.get_density() * 100\n","        print(f\"   Pre-pruning density: {pre_prune_density:.1f}%\")\n","\n","        # Apply additional pruning\n","        print(f\"   Applying {CONFIG['late_pruning_asd']*100:.0f}% additional pruning...\")\n","        prune_stats = asd_mgr.prune_fraction_of_remaining(CONFIG['late_pruning_asd'])\n","        asd_density = asd_mgr.get_density() * 100\n","\n","        print(f\"   Pruning details:\")\n","        for layer_name, stats in prune_stats.items():\n","            print(f\"     {layer_name}: removed {stats['removed']:,} weights, {stats['remaining']:,} remaining ({stats['fraction']*100:.1f}% removed)\")\n","\n","        print(f\"   Post-pruning density: {asd_density:.1f}%\")\n","\n","        # Fine-tune\n","        print(f\"\\n   Fine-tuning for {CONFIG['late_finetune_epochs']} epochs...\")\n","        train_taskgated_with_curves(\n","            asd_model, loaders,\n","            epochs=CONFIG['late_finetune_epochs'],\n","            lr=CONFIG['finetune_lr'],\n","            pruning_manager=asd_mgr,\n","            verbose=True,\n","            track_test_accuracy=True\n","        )\n","\n","        key_asd = f\"late_asd_{density_pct}\"\n","        results_asd = comprehensive_evaluation(\n","            asd_model, loaders,\n","            f\"LATE ASD (from {density_pct}% → {asd_density:.1f}%)\",\n","            print_results=True\n","        )\n","        results_asd['early_density'] = early_density\n","        results_asd['final_density'] = asd_density\n","        results_asd['pruning_fraction'] = CONFIG['late_pruning_asd']\n","        all_results['late_stage_asd'][key_asd] = results_asd\n","\n","        # ----------------------------------------------------------------\n","        # COMPARISON: Normal vs ASD\n","        # ----------------------------------------------------------------\n","        print(\"\\n\" + \"-\"*60)\n","        print(f\"   COMPARISON: Normal vs ASD (from {density_pct}% early density)\")\n","        print(\"-\"*60)\n","\n","        comparison = {\n","            'early_density': early_density,\n","            'normal_final_density': normal_density,\n","            'asd_final_density': asd_density,\n","            'visual_diff': results_normal['visual_clear'] - results_asd['visual_clear'],\n","            'voice_diff': results_normal['voice_clear'] - results_asd['voice_clear'],\n","            'stress_diff': results_normal.get('visual_stress_high', 0) - results_asd.get('visual_stress_high', 0),\n","            'ambig_diff': results_normal.get('visual_ambig_ambiguous', 0) - results_asd.get('visual_ambig_ambiguous', 0),\n","            'blend_ambig_diff': results_normal.get('visual_blend50_ambig', 0) - results_asd.get('visual_blend50_ambig', 0)\n","        }\n","        all_results['comparisons'][density_pct] = comparison\n","\n","        print(f\"\\n   {'Metric':<25} {'Normal':>12} {'ASD':>12} {'Diff (N-A)':>12}\")\n","        print(f\"   {'-'*65}\")\n","        print(f\"   {'Final Density':<25} {normal_density:>11.1f}% {asd_density:>11.1f}% {'---':>12}\")\n","        print(f\"   {'Visual Accuracy':<25} {results_normal['visual_clear']:>11.1f}% {results_asd['visual_clear']:>11.1f}% {comparison['visual_diff']:>+11.1f}%\")\n","        print(f\"   {'Voice Accuracy':<25} {results_normal['voice_clear']:>11.1f}% {results_asd['voice_clear']:>11.1f}% {comparison['voice_diff']:>+11.1f}%\")\n","        print(f\"   {'Stress Tolerance (high)':<25} {results_normal.get('visual_stress_high', 0):>11.1f}% {results_asd.get('visual_stress_high', 0):>11.1f}% {comparison['stress_diff']:>+11.1f}%\")\n","        print(f\"   {'Ambiguity Tolerance':<25} {results_normal.get('visual_ambig_ambiguous', 0):>11.1f}% {results_asd.get('visual_ambig_ambiguous', 0):>11.1f}% {comparison['ambig_diff']:>+11.1f}%\")\n","        print(f\"   {'Blend + Ambiguity':<25} {results_normal.get('visual_blend50_ambig', 0):>11.1f}% {results_asd.get('visual_blend50_ambig', 0):>11.1f}% {comparison['blend_ambig_diff']:>+11.1f}%\")\n","\n","        # Interpretation\n","        print(f\"\\n   Interpretation:\")\n","        if comparison['visual_diff'] > 0:\n","            print(f\"     → Normal outperforms ASD by {comparison['visual_diff']:.1f}% on visual task\")\n","        elif comparison['visual_diff'] < 0:\n","            print(f\"     → ASD outperforms Normal by {-comparison['visual_diff']:.1f}% on visual task\")\n","        else:\n","            print(f\"     → Normal and ASD perform equally on visual task\")\n","\n","        if comparison['stress_diff'] > 0:\n","            print(f\"     → Normal has better stress tolerance by {comparison['stress_diff']:.1f}%\")\n","        elif comparison['stress_diff'] < 0:\n","            print(f\"     → ASD has better stress tolerance by {-comparison['stress_diff']:.1f}%\")\n","\n","    # ========================================================================\n","    # COMPREHENSIVE SUMMARY TABLES\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" COMPREHENSIVE SUMMARY TABLES\")\n","    print(\"=\"*80)\n","\n","    # Early Stage Summary\n","    print(\"\\n\" + \"-\"*70)\n","    print(\" TABLE 1: EARLY STAGE RESULTS (Density Sweep)\")\n","    print(\"-\"*70)\n","    print(f\"\\n {'Density':>10} {'Visual':>10} {'Voice':>10} {'Stress Hi':>12} {'Ambiguous':>12} {'Blend+Ambig':>12}\")\n","    print(\" \" + \"-\"*75)\n","\n","    for density_pct in sorted([int(d*100) for d in CONFIG['early_density_levels'] if d >= 0.1]):\n","        key = f\"early_{density_pct}\"\n","        if key in all_results['early_stage']:\n","            r = all_results['early_stage'][key]\n","            print(f\" {r['actual_density']:>9.1f}% {r['visual_clear']:>9.1f}% {r['voice_clear']:>9.1f}% \"\n","                  f\"{r.get('visual_stress_high', 0):>11.1f}% {r.get('visual_ambig_ambiguous', 0):>11.1f}% \"\n","                  f\"{r.get('visual_blend50_ambig', 0):>11.1f}%\")\n","\n","    # Late Stage Comparison Table\n","    print(\"\\n\" + \"-\"*70)\n","    print(\" TABLE 2: LATE STAGE COMPARISON (Normal vs ASD)\")\n","    print(\"-\"*70)\n","    print(f\"\\n Normal: {CONFIG['late_pruning_normal']*100:.0f}% pruned | ASD: {CONFIG['late_pruning_asd']*100:.0f}% pruned\\n\")\n","    print(f\" {'Early%':>8} {'N-Dens':>8} {'A-Dens':>8} {'N-Vis':>8} {'A-Vis':>8} {'Diff':>8} \"\n","          f\"{'N-Str':>8} {'A-Str':>8} {'Diff':>8}\")\n","    print(\" \" + \"-\"*85)\n","\n","    for density_pct in sorted(all_results['comparisons'].keys()):\n","        comp = all_results['comparisons'][density_pct]\n","        key_n = f\"late_normal_{density_pct}\"\n","        key_a = f\"late_asd_{density_pct}\"\n","\n","        r_n = all_results['late_stage_normal'][key_n]\n","        r_a = all_results['late_stage_asd'][key_a]\n","\n","        print(f\" {density_pct:>7}% {r_n['final_density']:>7.1f}% {r_a['final_density']:>7.1f}% \"\n","              f\"{r_n['visual_clear']:>7.1f}% {r_a['visual_clear']:>7.1f}% {comp['visual_diff']:>+7.1f}% \"\n","              f\"{r_n.get('visual_stress_high', 0):>7.1f}% {r_a.get('visual_stress_high', 0):>7.1f}% \"\n","              f\"{comp['stress_diff']:>+7.1f}%\")\n","\n","    # Progression Table\n","    print(\"\\n\" + \"-\"*70)\n","    print(\" TABLE 3: EARLY → LATE PROGRESSION\")\n","    print(\"-\"*70)\n","    print(f\"\\n {'Early%':>8} {'Early-Vis':>10} {'N-Vis':>10} {'A-Vis':>10} {'E→N Δ':>10} {'E→A Δ':>10}\")\n","    print(\" \" + \"-\"*65)\n","\n","    for density_pct in sorted(all_results['comparisons'].keys()):\n","        early_key = f\"early_{density_pct}\"\n","        key_n = f\"late_normal_{density_pct}\"\n","        key_a = f\"late_asd_{density_pct}\"\n","\n","        r_e = all_results['early_stage'][early_key]\n","        r_n = all_results['late_stage_normal'][key_n]\n","        r_a = all_results['late_stage_asd'][key_a]\n","\n","        e_vis = r_e['visual_clear']\n","        n_vis = r_n['visual_clear']\n","        a_vis = r_a['visual_clear']\n","        e_to_n = n_vis - e_vis\n","        e_to_a = a_vis - e_vis\n","\n","        print(f\" {density_pct:>7}% {e_vis:>9.1f}% {n_vis:>9.1f}% {a_vis:>9.1f}% {e_to_n:>+9.1f}% {e_to_a:>+9.1f}%\")\n","\n","    # ========================================================================\n","    # ANALYSIS\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" DETAILED ANALYSIS\")\n","    print(\"=\"*80)\n","\n","    # Find optimal early density\n","    early_visuals = [(d, all_results['early_stage'][f'early_{d}']['visual_clear'])\n","                     for d in sorted([int(x*100) for x in CONFIG['early_density_levels'] if x >= 0.1])\n","                     if f'early_{d}' in all_results['early_stage']]\n","    best_early_density, best_early_acc = max(early_visuals, key=lambda x: x[1])\n","\n","    # Average differences\n","    avg_visual_diff = np.mean([c['visual_diff'] for c in all_results['comparisons'].values()])\n","    avg_stress_diff = np.mean([c['stress_diff'] for c in all_results['comparisons'].values()])\n","    avg_ambig_diff = np.mean([c['ambig_diff'] for c in all_results['comparisons'].values()])\n","\n","    # Standard deviations\n","    std_visual_diff = np.std([c['visual_diff'] for c in all_results['comparisons'].values()])\n","    std_stress_diff = np.std([c['stress_diff'] for c in all_results['comparisons'].values()])\n","\n","    print(f\"\"\"\n"," EARLY STAGE FINDINGS:\n"," =====================\n","\n"," Optimal Early Density:\n","   - Best visual accuracy: {best_early_acc:.1f}% at {best_early_density}% density\n","   - This suggests that moderate pruning may help, but excessive pruning hurts\n","\n"," Density-Performance Relationship:\n","   - Lower densities (10-30%): Likely degraded performance due to insufficient capacity\n","   - Moderate densities (40-70%): May achieve good balance\n","   - High densities (80-100%): Full capacity, but potentially over-parameterized\n","\n"," Learning Dynamics:\n","   - Sparse networks may learn more slowly but generalize differently\n","   - Dense networks learn faster but may overfit to training distribution\n","    \"\"\")\n","\n","    print(f\"\"\"\n"," LATE STAGE FINDINGS (Normal vs ASD):\n"," ====================================\n","\n"," Overall Differences (Normal - ASD, averaged across all early densities):\n","   - Visual accuracy: {avg_visual_diff:+.2f}% ± {std_visual_diff:.2f}%\n","   - Stress tolerance: {avg_stress_diff:+.2f}% ± {std_stress_diff:.2f}%\n","   - Ambiguity tolerance: {avg_ambig_diff:+.2f}%\n","\n"," Statistical Interpretation:\n","   - Positive difference = Normal outperforms ASD\n","   - Negative difference = ASD outperforms Normal\n","\n"," Conclusion: {\"Normal condition generally performs BETTER\" if avg_visual_diff > 0 else \"ASD condition performs comparably or BETTER\"}\n","   → Heavier late pruning (ASD) {\"HURTS\" if avg_visual_diff > 0 else \"does NOT necessarily hurt\"} performance\n","    \"\"\")\n","\n","    # Density-dependent effect analysis\n","    print(\"\\n DENSITY-DEPENDENT EFFECTS:\")\n","    print(\" \" + \"-\"*60)\n","    print(f\"\\n How does early density affect the Normal-ASD gap?\\n\")\n","\n","    for density_pct in sorted(all_results['comparisons'].keys()):\n","        comp = all_results['comparisons'][density_pct]\n","        effect = \"Normal BETTER\" if comp['visual_diff'] > 0 else \"ASD BETTER\" if comp['visual_diff'] < 0 else \"EQUAL\"\n","        magnitude = abs(comp['visual_diff'])\n","\n","        # Interpretation\n","        if density_pct <= 30:\n","            context = \"(low starting density - already resource-constrained)\"\n","        elif density_pct <= 60:\n","            context = \"(moderate starting density)\"\n","        else:\n","            context = \"(high starting density - ample resources)\"\n","\n","        print(f\"   {density_pct}% early density:\")\n","        print(f\"     → {effect} by {magnitude:.1f}% {context}\")\n","        print(f\"     → Final densities: Normal={comp['normal_final_density']:.1f}%, ASD={comp['asd_final_density']:.1f}%\")\n","\n","    # Key insights\n","    print(f\"\"\"\n","\n"," KEY INSIGHTS:\n"," =============\n","\n"," 1. Interaction Effect:\n","    The impact of late pruning depends critically on early density.\n","    - High early density provides \"buffer\" against late pruning damage\n","    - Low early density leaves network vulnerable to any further pruning\n","\n"," 2. Resilience Patterns:\n","    Networks with more initial connections can better absorb pruning\n","    without catastrophic performance loss.\n","\n"," 3. Implications for ASD Modeling:\n","    If ASD involves altered pruning dynamics, both timing AND magnitude matter:\n","    - Early hyper-connectivity + insufficient late pruning = one pattern\n","    - Normal early + excessive late pruning = different pattern (tested here)\n","\n"," 4. Stress and Ambiguity:\n","    These secondary metrics often show larger Normal-ASD gaps than basic accuracy,\n","    suggesting pruning affects robustness more than raw performance.\n","    \"\"\")\n","\n","    return all_results\n","\n","\n","# ============================================================================\n","# SECTION 8: MAIN\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"\\n\" + \"#\"*80)\n","    print(\"#\" + \" DEVELOPMENTAL PRUNING SIMULATION FOR ASD \".center(78) + \"#\")\n","    print(\"#\" + \" VERSION 9.2: DENSITY SWEEP WITH DIFFERENTIAL PRUNING \".center(78) + \"#\")\n","    print(\"#\" + \" EXPERIMENT 1 ONLY \".center(78) + \"#\")\n","    print(\"#\"*80)\n","\n","    print(\"\"\"\n"," ============================================================================\n"," EXPERIMENT 1: DENSITY SWEEP WITH DIFFERENTIAL LATE PRUNING\n"," ============================================================================\n","\n"," OBJECTIVE:\n"," ----------\n"," Understand how initial network density (early pruning) affects:\n","   1. Learning capacity and task performance\n","   2. Resilience to subsequent pruning\n","   3. Differential outcomes between Normal and ASD pruning regimes\n","\n"," EARLY STAGE:\n"," ------------\n","   • Test densities: 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%\n","   • Each model starts from trained baseline\n","   • Prune to target density, then train for 15 epochs\n","   • Evaluate on: accuracy, stress tolerance, ambiguity handling\n","\n"," LATE STAGE:\n"," -----------\n","   • For each early density, create two conditions:\n","     - Normal: Remove 20% of remaining weights\n","     - ASD: Remove 50% of remaining weights\n","   • Fine-tune each for 10 epochs\n","   • Compare Normal vs ASD outcomes\n","\n"," METRICS:\n"," --------\n","   • Visual task accuracy (primary)\n","   • Voice task accuracy (secondary, conflicting task)\n","   • Stress tolerance (performance under noise injection)\n","   • Ambiguity tolerance (performance with mixed task signals)\n","   • Blended input handling (combining sensory streams)\n","\n"," ============================================================================\n","    \"\"\")\n","\n","    # Run experiment\n","    print(\"\\n Starting Experiment 1...\")\n","    sweep_results = run_density_sweep_experiment()\n","\n","    # Final summary\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" EXPERIMENT 1 COMPLETE\")\n","    print(\"=\"*80)\n","\n","    print(\"\"\"\n"," RESULTS STRUCTURE:\n"," ==================\n","\n"," sweep_results dictionary contains:\n","\n","   'baseline':\n","     Results for full density (100%) baseline network\n","\n","   'early_stage':\n","     Results for each density level (keys: 'early_10', 'early_20', ..., 'early_100')\n","     Each contains: visual_clear, voice_clear, stress metrics, ambiguity metrics, etc.\n","\n","   'late_stage_normal':\n","     Results after Normal pruning (20% removed) from each early state\n","     Keys: 'late_normal_10', 'late_normal_20', ..., 'late_normal_100'\n","\n","   'late_stage_asd':\n","     Results after ASD pruning (50% removed) from each early state\n","     Keys: 'late_asd_10', 'late_asd_20', ..., 'late_asd_100'\n","\n","   'comparisons':\n","     Direct Normal vs ASD comparisons at each early density\n","     Keys: 10, 20, 30, ..., 100 (integer density values)\n","     Each contains: visual_diff, stress_diff, ambig_diff, etc.\n","\n","   'learning_curves':\n","     Training history (loss, accuracy per epoch) for baseline and each early density\n","    \"\"\")\n","\n","    print(\"=\"*80)\n","    print(\" END OF EXPERIMENT 1\")\n","    print(\"=\"*80 + \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"2iwchPUwbAse"},"source":["# The End"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOnm28Yj3jOPnNveh8Dmqmk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}